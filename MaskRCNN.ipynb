{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51a9f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mindspore import context\n",
    "import mindspore.nn as nn\n",
    "from mindspore.ops import operations as P\n",
    "from mindspore.common.tensor import Tensor\n",
    "from mindspore.ops import functional as F\n",
    "from mindspore.ops import composite as C\n",
    "from mindspore.nn import layer as L\n",
    "from mindspore.nn import Momentum\n",
    "from mindspore.common.parameter import Parameter\n",
    "from mindspore.common.initializer import initializer\n",
    "import mindspore.common.dtype as mstype\n",
    "import os\n",
    "import time\n",
    "from numpy import random\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as maskUtils\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import mindspore.dataset as de\n",
    "from mindspore.mindrecord import FileWriter\n",
    "import mindspore.dataset.vision as vision\n",
    "from mindspore import ParameterTuple\n",
    "import mindspore.ops as ops\n",
    "import mindspore as ms\n",
    "import matplotlib.pyplot as plt\n",
    "from mindspore.train import Model\n",
    "from mindspore.train.callback import Callback\n",
    "from mindspore.train.callback import CheckpointConfig, ModelCheckpoint, TimeMonitor\n",
    "from mindspore.train.serialization import load_checkpoint, load_param_into_net\n",
    "\n",
    "np_cast_type = np.float32\n",
    "time_stamp_init = time.time()\n",
    "time_stamp_first = time.time()\n",
    "\n",
    "\n",
    "class ResNet(nn.Cell):\n",
    "    \"\"\"\n",
    "    ResNet architecture.\n",
    "\n",
    "    Args:\n",
    "        block (Cell): Block for network.\n",
    "        layer_nums (list): Numbers of block in different layers.\n",
    "        in_channels (list): Input channel in each layer.\n",
    "        out_channels (list): Output channel in each layer.\n",
    "        weights_update (bool): Weight update flag.\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        >>> ResNet(ResidualBlock,\n",
    "        >>>        [3, 4, 6, 3],\n",
    "        >>>        [64, 256, 512, 1024],\n",
    "        >>>        [256, 512, 1024, 2048],\n",
    "        >>>        False)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 block,\n",
    "                 layer_nums,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 weights_update=False):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        if not len(layer_nums) == len(in_channels) == len(out_channels) == 4:\n",
    "            raise ValueError(\"the length of \"\n",
    "                             \"layer_num, inchannel, outchannel list must be 4!\")\n",
    "\n",
    "        bn_training = False\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, pad_mode='pad')\n",
    "        self.bn1 = nn.BatchNorm2d(64, affine=bn_training, use_batch_statistics=bn_training)\n",
    "        self.relu = P.ReLU()\n",
    "        self.maxpool = P.MaxPool(kernel_size=3, strides=2, pad_mode=\"SAME\")\n",
    "        self.weights_update = weights_update\n",
    "\n",
    "        if not self.weights_update:\n",
    "            self.conv1.weight.requires_grad = False\n",
    "\n",
    "        self.layer1 = self._make_layer(block,\n",
    "                                       layer_nums[0],\n",
    "                                       in_channel=in_channels[0],\n",
    "                                       out_channel=out_channels[0],\n",
    "                                       stride=1,\n",
    "                                       training=bn_training,\n",
    "                                       weights_update=self.weights_update)\n",
    "        self.layer2 = self._make_layer(block,\n",
    "                                       layer_nums[1],\n",
    "                                       in_channel=in_channels[1],\n",
    "                                       out_channel=out_channels[1],\n",
    "                                       stride=2,\n",
    "                                       training=bn_training,\n",
    "                                       weights_update=True)\n",
    "        self.layer3 = self._make_layer(block,\n",
    "                                       layer_nums[2],\n",
    "                                       in_channel=in_channels[2],\n",
    "                                       out_channel=out_channels[2],\n",
    "                                       stride=2,\n",
    "                                       training=bn_training,\n",
    "                                       weights_update=True)\n",
    "        self.layer4 = self._make_layer(block,\n",
    "                                       layer_nums[3],\n",
    "                                       in_channel=in_channels[3],\n",
    "                                       out_channel=out_channels[3],\n",
    "                                       stride=2,\n",
    "                                       training=bn_training,\n",
    "                                       weights_update=True)\n",
    "\n",
    "    def _make_layer(self, block, layer_num, in_channel, out_channel, stride, training=False, weights_update=False):\n",
    "        \"\"\"Make block layer.\"\"\"\n",
    "        layers = []\n",
    "        down_sample = False\n",
    "        if stride != 1 or in_channel != out_channel:\n",
    "            down_sample = True\n",
    "        resblk = block(in_channel,\n",
    "                       out_channel,\n",
    "                       stride=stride,\n",
    "                       down_sample=down_sample,\n",
    "                       training=training,\n",
    "                       weights_update=weights_update)\n",
    "        layers.append(resblk)\n",
    "\n",
    "        for _ in range(1, layer_num):\n",
    "            resblk = block(out_channel, out_channel, stride=1, training=training, weights_update=weights_update)\n",
    "            layers.append(resblk)\n",
    "\n",
    "        return nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        c1 = self.maxpool(x)\n",
    "\n",
    "        c2 = self.layer1(c1)\n",
    "        identity = c2\n",
    "        if not self.weights_update:\n",
    "            identity = F.stop_gradient(c2)\n",
    "        c3 = self.layer2(identity)\n",
    "        c4 = self.layer3(c3)\n",
    "        c5 = self.layer4(c4)\n",
    "\n",
    "        return identity, c3, c4, c5\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Cell):\n",
    "    \"\"\"\n",
    "    ResNet V1 residual block definition.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int) - Input channel.\n",
    "        out_channels (int) - Output channel.\n",
    "        stride (int) - Stride size for the initial convolutional layer. Default: 1.\n",
    "        down_sample (bool) - If to do the downsample in block. Default: False.\n",
    "        momentum (float) - Momentum for batchnorm layer. Default: 0.1.\n",
    "        training (bool) - Training flag. Default: False.\n",
    "        weights_updata (bool) - Weights update flag. Default: False.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "\n",
    "    Examples:\n",
    "        ResidualBlock(3,256,stride=2,down_sample=True)\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 stride=1,\n",
    "                 down_sample=False,\n",
    "                 momentum=0.1,\n",
    "                 training=False,\n",
    "                 weights_update=False):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        self.affine = weights_update\n",
    "\n",
    "        out_chls = out_channels // self.expansion\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_chls, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(out_chls, momentum=momentum, affine=self.affine, use_batch_statistics=training)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_chls, out_chls, kernel_size=3, stride=stride, pad_mode='pad', padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_chls, momentum=momentum, affine=self.affine, use_batch_statistics=training)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(out_chls, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels, momentum=momentum, affine=self.affine, use_batch_statistics=training)\n",
    "\n",
    "        if training:\n",
    "            self.bn1 = self.bn1.set_train()\n",
    "            self.bn2 = self.bn2.set_train()\n",
    "            self.bn3 = self.bn3.set_train()\n",
    "\n",
    "        if not weights_update:\n",
    "            self.conv1.weight.requires_grad = False\n",
    "            self.conv2.weight.requires_grad = False\n",
    "            self.conv3.weight.requires_grad = False\n",
    "\n",
    "        self.relu = P.ReLU()\n",
    "        self.downsample = down_sample\n",
    "        if self.downsample:\n",
    "            self.conv_down_sample = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0)\n",
    "            self.bn_down_sample = nn.BatchNorm2d(out_channels, momentum=momentum, affine=self.affine,\n",
    "                                                 use_batch_statistics=training)\n",
    "            if training:\n",
    "                self.bn_down_sample = self.bn_down_sample.set_train()\n",
    "            if not weights_update:\n",
    "                self.conv_down_sample.weight.requires_grad = False\n",
    "        self.add = P.Add()\n",
    "\n",
    "    def construct(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample:\n",
    "            identity = self.conv_down_sample(identity)\n",
    "            identity = self.bn_down_sample(identity)\n",
    "\n",
    "        out = self.add(out, identity)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class FeatPyramidNeck(nn.Cell):\n",
    "    \"\"\"\n",
    "    Feature pyramid network cell, usually uses as network neck.\n",
    "\n",
    "    Applies the convolution on multiple, input feature maps\n",
    "    and output feature map with same channel size. if required num of\n",
    "    output larger then num of inputs, add extra maxpooling for further\n",
    "    downsampling;\n",
    "\n",
    "    Args:\n",
    "        in_channels (tuple) - Channel size of input feature maps.\n",
    "        out_channels (int) - Channel size output.\n",
    "        num_outs (int) - Num of output features.\n",
    "\n",
    "    Returns:\n",
    "        Tuple, with tensors of same channel size.\n",
    "\n",
    "    Examples:\n",
    "        neck = FeatPyramidNeck([100,200,300], 50, 4, config.feature_shapes)\n",
    "        input_data = (normal(0,0.1,(1,c,1280//(4*2**i), 768//(4*2**i)),\n",
    "                      dtype=np.float32) \\\n",
    "                      for i, c in enumerate(config.fpn_in_channels))\n",
    "        x = neck(input_data)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 num_outs,\n",
    "                 feature_shapes):\n",
    "        super(FeatPyramidNeck, self).__init__()\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "\n",
    "        self.num_outs = num_outs\n",
    "        self.in_channels = in_channels\n",
    "        self.fpn_layer = len(self.in_channels)\n",
    "\n",
    "        assert not self.num_outs < len(in_channels)\n",
    "\n",
    "        self.lateral_convs_list_ = []\n",
    "        self.fpn_convs_ = []\n",
    "\n",
    "        for _, channel in enumerate(in_channels):\n",
    "            l_conv = nn.Conv2d(channel, out_channels, kernel_size=1, stride=1,\n",
    "                               padding=0, pad_mode='valid').to_float(self.cast_type)\n",
    "            fpn_conv = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1,\n",
    "                                 padding=0, pad_mode='same').to_float(self.cast_type)\n",
    "            self.lateral_convs_list_.append(l_conv)\n",
    "            self.fpn_convs_.append(fpn_conv)\n",
    "        self.lateral_convs_list = nn.layer.CellList(self.lateral_convs_list_)\n",
    "        self.fpn_convs_list = nn.layer.CellList(self.fpn_convs_)\n",
    "        self.interpolate1 = P.ResizeBilinear(feature_shapes[2])\n",
    "        self.interpolate2 = P.ResizeBilinear(feature_shapes[1])\n",
    "        self.interpolate3 = P.ResizeBilinear(feature_shapes[0])\n",
    "        self.cast = P.Cast()\n",
    "        self.maxpool = P.MaxPool(kernel_size=1, strides=2, pad_mode=\"same\")\n",
    "\n",
    "    def construct(self, inputs):\n",
    "        x = ()\n",
    "        for i in range(self.fpn_layer):\n",
    "            x += (self.lateral_convs_list[i](inputs[i]),)\n",
    "\n",
    "        y = (x[3],)\n",
    "        y = y + (x[2] + self.cast(self.interpolate1(y[self.fpn_layer - 4]), self.cast_type),)\n",
    "        y = y + (x[1] + self.cast(self.interpolate2(y[self.fpn_layer - 3]), self.cast_type),)\n",
    "        y = y + (x[0] + self.cast(self.interpolate3(y[self.fpn_layer - 2]), self.cast_type),)\n",
    "\n",
    "        z = ()\n",
    "        for i in range(self.fpn_layer - 1, -1, -1):\n",
    "            z = z + (y[i],)\n",
    "\n",
    "        outs = ()\n",
    "        for i in range(self.fpn_layer):\n",
    "            outs = outs + (self.fpn_convs_list[i](z[i]),)\n",
    "\n",
    "        for i in range(self.num_outs - self.fpn_layer):\n",
    "            outs = outs + (self.maxpool(outs[3]),)\n",
    "        return outs\n",
    "\n",
    "\n",
    "class BboxAssignSample(nn.Cell):\n",
    "    \"\"\"\n",
    "    Bbox assigner and sampler definition.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Config.\n",
    "        batch_size (int): Batchsize.\n",
    "        num_bboxes (int): The anchor nums.\n",
    "        add_gt_as_proposals (bool): add gt bboxes as proposals flag.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "        bbox_targets: bbox location, (batch_size, num_bboxes, 4)\n",
    "        bbox_weights: bbox weights, (batch_size, num_bboxes, 1)\n",
    "        labels: label for every bboxes, (batch_size, num_bboxes, 1)\n",
    "        label_weights: label weight for every bboxes, (batch_size, num_bboxes, 1)\n",
    "\n",
    "    Examples:\n",
    "        BboxAssignSample(config, 2, 1024, True)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, batch_size, num_bboxes, add_gt_as_proposals):\n",
    "        super(BboxAssignSample, self).__init__()\n",
    "        cfg = config\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.neg_iou_thr = Tensor(cfg.neg_iou_thr, self.cast_type)\n",
    "        self.pos_iou_thr = Tensor(cfg.pos_iou_thr, self.cast_type)\n",
    "        self.min_pos_iou = Tensor(cfg.min_pos_iou, self.cast_type)\n",
    "        self.zero_thr = Tensor(0.0, self.cast_type)\n",
    "\n",
    "        self.num_bboxes = num_bboxes\n",
    "        self.num_gts = cfg.num_gts\n",
    "        self.num_expected_pos = cfg.num_expected_pos\n",
    "        self.num_expected_neg = cfg.num_expected_neg\n",
    "        self.add_gt_as_proposals = add_gt_as_proposals\n",
    "\n",
    "        if self.add_gt_as_proposals:\n",
    "            self.label_inds = Tensor(np.arange(1, self.num_gts + 1))\n",
    "\n",
    "        self.concat = P.Concat(axis=0)\n",
    "        self.max_gt = P.ArgMaxWithValue(axis=0)\n",
    "        self.max_anchor = P.ArgMaxWithValue(axis=1)\n",
    "        self.sum_inds = P.ReduceSum()\n",
    "        self.iou = P.IOU()\n",
    "        self.greaterequal = P.GreaterEqual()\n",
    "        self.greater = P.Greater()\n",
    "        self.select = P.Select()\n",
    "        self.gatherND = P.GatherNd()\n",
    "        self.squeeze = P.Squeeze()\n",
    "        self.cast = P.Cast()\n",
    "        self.logicaland = P.LogicalAnd()\n",
    "        self.less = P.Less()\n",
    "        self.random_choice_with_mask_pos = P.RandomChoiceWithMask(self.num_expected_pos)\n",
    "        self.random_choice_with_mask_neg = P.RandomChoiceWithMask(self.num_expected_neg)\n",
    "        self.reshape = P.Reshape()\n",
    "        self.equal = P.Equal()\n",
    "        self.bounding_box_encode = P.BoundingBoxEncode(means=(0.0, 0.0, 0.0, 0.0), stds=(1.0, 1.0, 1.0, 1.0))\n",
    "        self.scatterNdUpdate = P.ScatterNdUpdate()\n",
    "        self.scatterNd = P.ScatterNd()\n",
    "        self.logicalnot = P.LogicalNot()\n",
    "        self.tile = P.Tile()\n",
    "        self.zeros_like = P.ZerosLike()\n",
    "\n",
    "        self.assigned_gt_inds = Tensor(np.array(-1 * np.ones(num_bboxes), dtype=np.int32))\n",
    "        self.assigned_gt_zeros = Tensor(np.array(np.zeros(num_bboxes), dtype=np.int32))\n",
    "        self.assigned_gt_ones = Tensor(np.array(np.ones(num_bboxes), dtype=np.int32))\n",
    "        self.assigned_gt_ignores = Tensor(np.array(-1 * np.ones(num_bboxes), dtype=np.int32))\n",
    "        self.assigned_pos_ones = Tensor(np.array(np.ones(self.num_expected_pos), dtype=np.int32))\n",
    "\n",
    "        self.check_neg_mask = Tensor(np.array(np.ones(self.num_expected_neg - self.num_expected_pos), dtype=bool))\n",
    "        self.range_pos_size = Tensor(np.arange(self.num_expected_pos).astype(self.np_cast_type))\n",
    "        self.check_gt_one = Tensor(np.array(-1 * np.ones((self.num_gts, 4)), dtype=self.np_cast_type))\n",
    "        self.check_anchor_two = Tensor(np.array(-2 * np.ones((self.num_bboxes, 4)), dtype=self.np_cast_type))\n",
    "\n",
    "    def construct(self, gt_bboxes_i, gt_labels_i, valid_mask, bboxes, gt_valids):\n",
    "        gt_bboxes_i = self.select(self.cast(self.tile(self.reshape(self.cast(gt_valids, mstype.int32), \\\n",
    "                                                                   (self.num_gts, 1)), (1, 4)), mstype.bool_),\n",
    "                                  gt_bboxes_i, self.check_gt_one)\n",
    "        bboxes = self.select(self.cast(self.tile(self.reshape(self.cast(valid_mask, mstype.int32), \\\n",
    "                                                              (self.num_bboxes, 1)), (1, 4)), mstype.bool_), bboxes,\n",
    "                             self.check_anchor_two)\n",
    "\n",
    "        overlaps = self.iou(bboxes, gt_bboxes_i)\n",
    "\n",
    "        max_overlaps_w_gt_index, max_overlaps_w_gt = self.max_gt(overlaps)\n",
    "        _, max_overlaps_w_ac = self.max_anchor(overlaps)\n",
    "\n",
    "        neg_sample_iou_mask = self.logicaland(self.greaterequal(max_overlaps_w_gt, self.zero_thr), \\\n",
    "                                              self.less(max_overlaps_w_gt, self.neg_iou_thr))\n",
    "        assigned_gt_inds2 = self.select(neg_sample_iou_mask, self.assigned_gt_zeros, self.assigned_gt_inds)\n",
    "\n",
    "        pos_sample_iou_mask = self.greaterequal(max_overlaps_w_gt, self.pos_iou_thr)\n",
    "        assigned_gt_inds3 = self.select(pos_sample_iou_mask, \\\n",
    "                                        max_overlaps_w_gt_index + self.assigned_gt_ones, assigned_gt_inds2)\n",
    "        assigned_gt_inds4 = assigned_gt_inds3\n",
    "        for j in range(self.num_gts):\n",
    "            max_overlaps_w_ac_j = max_overlaps_w_ac[j:j + 1:1]\n",
    "            overlaps_w_gt_j = self.squeeze(overlaps[j:j + 1:1, ::])\n",
    "\n",
    "            pos_mask_j = self.logicaland(self.greaterequal(max_overlaps_w_ac_j, self.min_pos_iou), \\\n",
    "                                         self.equal(overlaps_w_gt_j, max_overlaps_w_ac_j))\n",
    "\n",
    "            assigned_gt_inds4 = self.select(pos_mask_j, self.assigned_gt_ones + j, assigned_gt_inds4)\n",
    "\n",
    "        assigned_gt_inds5 = self.select(valid_mask, assigned_gt_inds4, self.assigned_gt_ignores)\n",
    "\n",
    "        pos_index, valid_pos_index = self.random_choice_with_mask_pos(self.greater(assigned_gt_inds5, 0))\n",
    "\n",
    "        pos_check_valid = self.cast(self.greater(assigned_gt_inds5, 0), self.cast_type)\n",
    "        pos_check_valid = self.sum_inds(pos_check_valid, -1)\n",
    "        valid_pos_index = self.less(self.range_pos_size, pos_check_valid)\n",
    "        pos_index = pos_index * self.reshape(self.cast(valid_pos_index, mstype.int32), (self.num_expected_pos, 1))\n",
    "\n",
    "        pos_assigned_gt_index = self.gatherND(assigned_gt_inds5, pos_index) - self.assigned_pos_ones\n",
    "        pos_assigned_gt_index = pos_assigned_gt_index * self.cast(valid_pos_index, mstype.int32)\n",
    "        pos_assigned_gt_index = self.reshape(pos_assigned_gt_index, (self.num_expected_pos, 1))\n",
    "\n",
    "        neg_index, valid_neg_index = self.random_choice_with_mask_neg(self.equal(assigned_gt_inds5, 0))\n",
    "\n",
    "        num_pos = self.cast(self.logicalnot(valid_pos_index), self.cast_type)\n",
    "        num_pos = self.sum_inds(num_pos, -1)\n",
    "        unvalid_pos_index = self.less(self.range_pos_size, num_pos)\n",
    "        valid_neg_index = self.logicaland(self.concat((self.check_neg_mask, unvalid_pos_index)), valid_neg_index)\n",
    "\n",
    "        pos_bboxes_ = self.gatherND(bboxes, pos_index)\n",
    "        pos_gt_bboxes_ = self.gatherND(gt_bboxes_i, pos_assigned_gt_index)\n",
    "        pos_gt_labels = self.gatherND(gt_labels_i, pos_assigned_gt_index)\n",
    "\n",
    "        pos_bbox_targets_ = self.bounding_box_encode(pos_bboxes_, pos_gt_bboxes_)\n",
    "\n",
    "        valid_pos_index = self.cast(valid_pos_index, mstype.int32)\n",
    "        valid_neg_index = self.cast(valid_neg_index, mstype.int32)\n",
    "        bbox_targets_total = self.scatterNd(pos_index, pos_bbox_targets_, (self.num_bboxes, 4))\n",
    "        bbox_weights_total = self.scatterNd(pos_index, valid_pos_index, (self.num_bboxes,))\n",
    "        labels_total = self.scatterNd(pos_index, pos_gt_labels, (self.num_bboxes,))\n",
    "        total_index = self.concat((pos_index, neg_index))\n",
    "        total_valid_index = self.concat((valid_pos_index, valid_neg_index))\n",
    "        label_weights_total = self.scatterNd(total_index, total_valid_index, (self.num_bboxes,))\n",
    "\n",
    "        return bbox_targets_total, self.cast(bbox_weights_total, mstype.bool_), \\\n",
    "               labels_total, self.cast(label_weights_total, mstype.bool_)\n",
    "\n",
    "\n",
    "class RpnRegClsBlock(nn.Cell):\n",
    "    \"\"\"\n",
    "    Rpn reg cls block for rpn layer\n",
    "\n",
    "    Args:\n",
    "        in_channels (int) - Input channels of shared convolution.\n",
    "        feat_channels (int) - Output channels of shared convolution.\n",
    "        num_anchors (int) - The anchor number.\n",
    "        cls_out_channels (int) - Output channels of classification convolution.\n",
    "        weight_conv (Tensor) - weight init for rpn conv.\n",
    "        bias_conv (Tensor) - bias init for rpn conv.\n",
    "        weight_cls (Tensor) - weight init for rpn cls conv.\n",
    "        bias_cls (Tensor) - bias init for rpn cls conv.\n",
    "        weight_reg (Tensor) - weight init for rpn reg conv.\n",
    "        bias_reg (Tensor) - bias init for rpn reg conv.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, output tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 feat_channels,\n",
    "                 num_anchors,\n",
    "                 cls_out_channels,\n",
    "                 weight_conv,\n",
    "                 bias_conv,\n",
    "                 weight_cls,\n",
    "                 bias_cls,\n",
    "                 weight_reg,\n",
    "                 bias_reg):\n",
    "        super(RpnRegClsBlock, self).__init__()\n",
    "        self.rpn_conv = nn.Conv2d(in_channels, feat_channels, kernel_size=3, stride=1, pad_mode='same',\n",
    "                                  has_bias=True, weight_init=weight_conv, bias_init=bias_conv)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.rpn_cls = nn.Conv2d(feat_channels, num_anchors * cls_out_channels, kernel_size=1, pad_mode='valid',\n",
    "                                 has_bias=True, weight_init=weight_cls, bias_init=bias_cls)\n",
    "        self.rpn_reg = nn.Conv2d(feat_channels, num_anchors * 4, kernel_size=1, pad_mode='valid',\n",
    "                                 has_bias=True, weight_init=weight_reg, bias_init=bias_reg)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.relu(self.rpn_conv(x))\n",
    "\n",
    "        x1 = self.rpn_cls(x)\n",
    "        x2 = self.rpn_reg(x)\n",
    "\n",
    "        return x1, x2\n",
    "\n",
    "\n",
    "class RPN(nn.Cell):\n",
    "    \"\"\"\n",
    "    ROI proposal network..\n",
    "\n",
    "    Args:\n",
    "        config (dict) - Config.\n",
    "        batch_size (int) - Batchsize.\n",
    "        in_channels (int) - Input channels of shared convolution.\n",
    "        feat_channels (int) - Output channels of shared convolution.\n",
    "        num_anchors (int) - The anchor number.\n",
    "        cls_out_channels (int) - Output channels of classification convolution.\n",
    "\n",
    "    Returns:\n",
    "        Tuple, tuple of output tensor.\n",
    "\n",
    "    Examples:\n",
    "        RPN(config=config, batch_size=2, in_channels=256, feat_channels=1024,\n",
    "            num_anchors=3, cls_out_channels=512)\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 batch_size,\n",
    "                 in_channels,\n",
    "                 feat_channels,\n",
    "                 num_anchors,\n",
    "                 cls_out_channels):\n",
    "        super(RPN, self).__init__()\n",
    "        cfg_rpn = config\n",
    "        if context.get_context(\"device_target\") == \"CPU\" or context.get_context(\"device_target\") == \"GPU\":\n",
    "            self.platform_dtype = np.float32\n",
    "            self.platform_mstype = mstype.float32\n",
    "        else:\n",
    "            self.platform_dtype = np.float32\n",
    "            self.platform_mstype = mstype.float32\n",
    "        self.num_bboxes = cfg_rpn.num_bboxes\n",
    "        self.slice_index = ()\n",
    "        self.feature_anchor_shape = ()\n",
    "        self.slice_index += (0,)\n",
    "        index = 0\n",
    "        for shape in cfg_rpn.feature_shapes:\n",
    "            self.slice_index += (self.slice_index[index] + shape[0] * shape[1] * num_anchors,)\n",
    "            self.feature_anchor_shape += (shape[0] * shape[1] * num_anchors * batch_size,)\n",
    "            index += 1\n",
    "\n",
    "        self.num_anchors = num_anchors\n",
    "        self.batch_size = batch_size\n",
    "        self.test_batch_size = cfg_rpn.test_batch_size\n",
    "        self.num_layers = 5\n",
    "        self.real_ratio = Tensor(np.ones((1, 1)).astype(self.platform_dtype))\n",
    "\n",
    "        self.rpn_convs_list = nn.layer.CellList(self._make_rpn_layer(self.num_layers, in_channels, feat_channels,\n",
    "                                                                     num_anchors, cls_out_channels))\n",
    "\n",
    "        self.transpose = P.Transpose()\n",
    "        self.reshape = P.Reshape()\n",
    "        self.concat = P.Concat(axis=0)\n",
    "        self.fill = P.Fill()\n",
    "        self.placeh1 = Tensor(np.ones((1,)).astype(self.platform_dtype))\n",
    "\n",
    "        self.trans_shape = (0, 2, 3, 1)\n",
    "\n",
    "        self.reshape_shape_reg = (-1, 4)\n",
    "        self.reshape_shape_cls = (-1,)\n",
    "        self.rpn_loss_reg_weight = Tensor(np.array(cfg_rpn.rpn_loss_reg_weight).astype(self.platform_dtype))\n",
    "        self.rpn_loss_cls_weight = Tensor(np.array(cfg_rpn.rpn_loss_cls_weight).astype(self.platform_dtype))\n",
    "        self.num_expected_total = Tensor(np.array(cfg_rpn.num_expected_neg * \\\n",
    "                                                  self.batch_size).astype(self.platform_dtype))\n",
    "        self.num_bboxes = cfg_rpn.num_bboxes\n",
    "        self.get_targets = BboxAssignSample(cfg_rpn, self.batch_size, self.num_bboxes, False)\n",
    "        self.CheckValid = P.CheckValid()\n",
    "        self.sum_loss = P.ReduceSum()\n",
    "        self.loss_cls = P.SigmoidCrossEntropyWithLogits()\n",
    "        self.loss_bbox = P.SmoothL1Loss(beta=1.0/9.0)\n",
    "        self.squeeze = P.Squeeze()\n",
    "        self.cast = P.Cast()\n",
    "        self.tile = P.Tile()\n",
    "        self.zeros_like = P.ZerosLike()\n",
    "        self.loss = Tensor(np.zeros((1,)).astype(self.platform_dtype))\n",
    "        self.clsloss = Tensor(np.zeros((1,)).astype(self.platform_dtype))\n",
    "        self.regloss = Tensor(np.zeros((1,)).astype(self.platform_dtype))\n",
    "\n",
    "    def _make_rpn_layer(self, num_layers, in_channels, feat_channels, num_anchors, cls_out_channels):\n",
    "        \"\"\"\n",
    "        make rpn layer for rpn proposal network\n",
    "\n",
    "        Args:\n",
    "        num_layers (int) - layer num.\n",
    "        in_channels (int) - Input channels of shared convolution.\n",
    "        feat_channels (int) - Output channels of shared convolution.\n",
    "        num_anchors (int) - The anchor number.\n",
    "        cls_out_channels (int) - Output channels of classification convolution.\n",
    "\n",
    "        Returns:\n",
    "        List, list of RpnRegClsBlock cells.\n",
    "        \"\"\"\n",
    "        rpn_layer = []\n",
    "\n",
    "        shp_weight_conv = (feat_channels, in_channels, 3, 3)\n",
    "        shp_bias_conv = (feat_channels,)\n",
    "        weight_conv = initializer('Normal', shape=shp_weight_conv, dtype=mstype.float32)\n",
    "        bias_conv = initializer(0, shape=shp_bias_conv, dtype=mstype.float32)\n",
    "\n",
    "        shp_weight_cls = (num_anchors * cls_out_channels, feat_channels, 1, 1)\n",
    "        shp_bias_cls = (num_anchors * cls_out_channels,)\n",
    "        weight_cls = initializer('Normal', shape=shp_weight_cls, dtype=mstype.float32)\n",
    "        bias_cls = initializer(0, shape=shp_bias_cls, dtype=mstype.float32)\n",
    "\n",
    "        shp_weight_reg = (num_anchors * 4, feat_channels, 1, 1)\n",
    "        shp_bias_reg = (num_anchors * 4,)\n",
    "        weight_reg = initializer('Normal', shape=shp_weight_reg, dtype=mstype.float32)\n",
    "        bias_reg = initializer(0, shape=shp_bias_reg, dtype=mstype.float32)\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            rpn_layer.append(RpnRegClsBlock(in_channels, feat_channels, num_anchors, cls_out_channels, \\\n",
    "                                            weight_conv, bias_conv, weight_cls, \\\n",
    "                                            bias_cls, weight_reg, bias_reg).to_float(self.platform_mstype))\n",
    "\n",
    "        for i in range(1, num_layers):\n",
    "            rpn_layer[i].rpn_conv.weight = rpn_layer[0].rpn_conv.weight\n",
    "            rpn_layer[i].rpn_cls.weight = rpn_layer[0].rpn_cls.weight\n",
    "            rpn_layer[i].rpn_reg.weight = rpn_layer[0].rpn_reg.weight\n",
    "\n",
    "            rpn_layer[i].rpn_conv.bias = rpn_layer[0].rpn_conv.bias\n",
    "            rpn_layer[i].rpn_cls.bias = rpn_layer[0].rpn_cls.bias\n",
    "            rpn_layer[i].rpn_reg.bias = rpn_layer[0].rpn_reg.bias\n",
    "\n",
    "        return rpn_layer\n",
    "\n",
    "    def construct(self, inputs, img_metas, anchor_list, gt_bboxes, gt_labels, gt_valids):\n",
    "        loss_print = ()\n",
    "        rpn_cls_score = ()\n",
    "        rpn_bbox_pred = ()\n",
    "        rpn_cls_score_total = ()\n",
    "        rpn_bbox_pred_total = ()\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x1, x2 = self.rpn_convs_list[i](inputs[i])\n",
    "\n",
    "            rpn_cls_score_total = rpn_cls_score_total + (x1,)\n",
    "            rpn_bbox_pred_total = rpn_bbox_pred_total + (x2,)\n",
    "\n",
    "            x1 = self.transpose(x1, self.trans_shape)\n",
    "            x1 = self.reshape(x1, self.reshape_shape_cls)\n",
    "\n",
    "            x2 = self.transpose(x2, self.trans_shape)\n",
    "            x2 = self.reshape(x2, self.reshape_shape_reg)\n",
    "\n",
    "            rpn_cls_score = rpn_cls_score + (x1,)\n",
    "            rpn_bbox_pred = rpn_bbox_pred + (x2,)\n",
    "\n",
    "        loss = self.loss\n",
    "        clsloss = self.clsloss\n",
    "        regloss = self.regloss\n",
    "        bbox_targets = ()\n",
    "        bbox_weights = ()\n",
    "        labels = ()\n",
    "        label_weights = ()\n",
    "\n",
    "        output = ()\n",
    "        if self.training:\n",
    "            for i in range(self.batch_size):\n",
    "                multi_level_flags = ()\n",
    "                anchor_list_tuple = ()\n",
    "\n",
    "                for j in range(self.num_layers):\n",
    "                    res = self.cast(self.CheckValid(anchor_list[j], self.squeeze(img_metas[i:i + 1, ::])),\n",
    "                                    mstype.int32)\n",
    "                    multi_level_flags = multi_level_flags + (res,)\n",
    "                    anchor_list_tuple = anchor_list_tuple + (anchor_list[j],)\n",
    "\n",
    "                valid_flag_list = self.concat(multi_level_flags)\n",
    "                anchor_using_list = self.concat(anchor_list_tuple)\n",
    "\n",
    "                gt_bboxes_i = self.squeeze(gt_bboxes[i:i + 1:1, ::])\n",
    "                gt_labels_i = self.squeeze(gt_labels[i:i + 1:1, ::])\n",
    "                gt_valids_i = self.squeeze(gt_valids[i:i + 1:1, ::])\n",
    "\n",
    "                bbox_target, bbox_weight, label, label_weight = self.get_targets(gt_bboxes_i,\n",
    "                                                                                 gt_labels_i,\n",
    "                                                                                 self.cast(valid_flag_list,\n",
    "                                                                                           mstype.bool_),\n",
    "                                                                                 anchor_using_list, gt_valids_i)\n",
    "\n",
    "                bbox_weight = self.cast(bbox_weight, self.platform_mstype)\n",
    "                label = self.cast(label, self.platform_mstype)\n",
    "                label_weight = self.cast(label_weight, self.platform_mstype)\n",
    "\n",
    "                for j in range(self.num_layers):\n",
    "                    begin = self.slice_index[j]\n",
    "                    end = self.slice_index[j + 1]\n",
    "                    stride = 1\n",
    "                    bbox_targets += (bbox_target[begin:end:stride, ::],)\n",
    "                    bbox_weights += (bbox_weight[begin:end:stride],)\n",
    "                    labels += (label[begin:end:stride],)\n",
    "                    label_weights += (label_weight[begin:end:stride],)\n",
    "\n",
    "            for i in range(self.num_layers):\n",
    "                bbox_target_using = ()\n",
    "                bbox_weight_using = ()\n",
    "                label_using = ()\n",
    "                label_weight_using = ()\n",
    "\n",
    "                for j in range(self.batch_size):\n",
    "                    bbox_target_using += (bbox_targets[i + (self.num_layers * j)],)\n",
    "                    bbox_weight_using += (bbox_weights[i + (self.num_layers * j)],)\n",
    "                    label_using += (labels[i + (self.num_layers * j)],)\n",
    "                    label_weight_using += (label_weights[i + (self.num_layers * j)],)\n",
    "\n",
    "                bbox_target_with_batchsize = self.concat(bbox_target_using)\n",
    "                bbox_weight_with_batchsize = self.concat(bbox_weight_using)\n",
    "                label_with_batchsize = self.concat(label_using)\n",
    "                label_weight_with_batchsize = self.concat(label_weight_using)\n",
    "\n",
    "                # stop\n",
    "                bbox_target_ = F.stop_gradient(bbox_target_with_batchsize)\n",
    "                bbox_weight_ = F.stop_gradient(bbox_weight_with_batchsize)\n",
    "                label_ = F.stop_gradient(label_with_batchsize)\n",
    "                label_weight_ = F.stop_gradient(label_weight_with_batchsize)\n",
    "\n",
    "                cls_score_i = rpn_cls_score[i]\n",
    "                reg_score_i = rpn_bbox_pred[i]\n",
    "\n",
    "                loss_cls = self.loss_cls(cls_score_i, label_)\n",
    "                loss_cls_item = loss_cls * label_weight_\n",
    "                loss_cls_item = self.sum_loss(loss_cls_item, (0,)) / self.num_expected_total\n",
    "\n",
    "                loss_reg = self.loss_bbox(reg_score_i, bbox_target_)\n",
    "                bbox_weight_ = self.tile(self.reshape(bbox_weight_, (self.feature_anchor_shape[i], 1)), (1, 4))\n",
    "                loss_reg = loss_reg * bbox_weight_\n",
    "                loss_reg_item = self.sum_loss(loss_reg, (1,))\n",
    "                loss_reg_item = self.sum_loss(loss_reg_item, (0,)) / self.num_expected_total\n",
    "\n",
    "                loss_total = self.rpn_loss_cls_weight * loss_cls_item + self.rpn_loss_reg_weight * loss_reg_item\n",
    "\n",
    "                loss += loss_total\n",
    "                loss_print += (loss_total, loss_cls_item, loss_reg_item)\n",
    "                clsloss += loss_cls_item\n",
    "                regloss += loss_reg_item\n",
    "\n",
    "                output = (loss, rpn_cls_score_total, rpn_bbox_pred_total, clsloss, regloss, loss_print)\n",
    "        else:\n",
    "            output = (self.placeh1, rpn_cls_score_total, rpn_bbox_pred_total, self.placeh1, self.placeh1, self.placeh1)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class Proposal(nn.Cell):\n",
    "    \"\"\"\n",
    "    Proposal subnet.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Config.\n",
    "        batch_size (int): Batchsize.\n",
    "        num_classes (int) - Class number.\n",
    "        use_sigmoid_cls (bool) - Select sigmoid or softmax function.\n",
    "        target_means (tuple) - Means for encode function. Default: (.0, .0, .0, .0).\n",
    "        target_stds (tuple) - Stds for encode function. Default: (1.0, 1.0, 1.0, 1.0).\n",
    "\n",
    "    Returns:\n",
    "        Tuple, tuple of output tensor,(proposal, mask).\n",
    "\n",
    "    Examples:\n",
    "        Proposal(config = config, batch_size = 1, num_classes = 81, use_sigmoid_cls = True, \\\n",
    "                 target_means=(.0, .0, .0, .0), target_stds=(1.0, 1.0, 1.0, 1.0))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 batch_size,\n",
    "                 num_classes,\n",
    "                 use_sigmoid_cls,\n",
    "                 target_means=(.0, .0, .0, .0),\n",
    "                 target_stds=(1.0, 1.0, 1.0, 1.0)\n",
    "                 ):\n",
    "        super(Proposal, self).__init__()\n",
    "        cfg = config\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.target_means = target_means\n",
    "        self.target_stds = target_stds\n",
    "        self.use_sigmoid_cls = use_sigmoid_cls\n",
    "        self.reshape_shape = (-1, 1)\n",
    "\n",
    "        if self.use_sigmoid_cls:\n",
    "            self.cls_out_channels = num_classes - 1\n",
    "            self.activation = P.Sigmoid()\n",
    "        else:\n",
    "            self.cls_out_channels = num_classes\n",
    "            self.activation = P.Softmax(axis=1)\n",
    "\n",
    "        if self.cls_out_channels <= 0:\n",
    "            raise ValueError('num_classes={} is too small'.format(num_classes))\n",
    "\n",
    "        self.num_pre = cfg.rpn_proposal_nms_pre\n",
    "        self.min_box_size = cfg.rpn_proposal_min_bbox_size\n",
    "        self.nms_thr = cfg.rpn_proposal_nms_thr\n",
    "        self.nms_post = cfg.rpn_proposal_nms_post\n",
    "        self.nms_across_levels = cfg.rpn_proposal_nms_across_levels\n",
    "        self.max_num = cfg.rpn_proposal_max_num\n",
    "        self.num_levels = cfg.fpn_num_outs\n",
    "\n",
    "        # Op Define\n",
    "        self.squeeze = P.Squeeze()\n",
    "        self.reshape = P.Reshape()\n",
    "        self.cast = P.Cast()\n",
    "\n",
    "        self.feature_shapes = cfg.feature_shapes\n",
    "\n",
    "        self.transpose_shape = (1, 2, 0)\n",
    "\n",
    "        self.decode = P.BoundingBoxDecode(max_shape=(cfg.img_height, cfg.img_width), \\\n",
    "                                          means=self.target_means, \\\n",
    "                                          stds=self.target_stds)\n",
    "\n",
    "        self.nms = P.NMSWithMask(self.nms_thr)\n",
    "        self.concat_axis0 = P.Concat(axis=0)\n",
    "        self.concat_axis1 = P.Concat(axis=1)\n",
    "        self.split = P.Split(axis=1, output_num=5)\n",
    "        self.min = P.Minimum()\n",
    "        self.gatherND = P.GatherNd()\n",
    "        self.slice = P.Slice()\n",
    "        self.select = P.Select()\n",
    "        self.greater = P.Greater()\n",
    "        self.transpose = P.Transpose()\n",
    "        self.tile = P.Tile()\n",
    "        self.set_train_local(config, training=True)\n",
    "\n",
    "        self.multi_10 = Tensor(10.0, self.cast_type)\n",
    "\n",
    "    def set_train_local(self, config, training=True):\n",
    "        \"\"\"Set training flag.\"\"\"\n",
    "        self.training_local = training\n",
    "\n",
    "        cfg = config\n",
    "        self.topK_stage1 = ()\n",
    "        self.topK_shape = ()\n",
    "        total_max_topk_input = 0\n",
    "        if not self.training_local:\n",
    "            self.num_pre = cfg.rpn_nms_pre\n",
    "            self.min_box_size = cfg.rpn_min_bbox_min_size\n",
    "            self.nms_thr = cfg.rpn_nms_thr\n",
    "            self.nms_post = cfg.rpn_nms_post\n",
    "            self.nms_across_levels = cfg.rpn_nms_across_levels\n",
    "            self.max_num = cfg.rpn_max_num\n",
    "\n",
    "        for shp in self.feature_shapes:\n",
    "            k_num = min(self.num_pre, (shp[0] * shp[1] * 3))\n",
    "            total_max_topk_input += k_num\n",
    "            self.topK_stage1 += (k_num,)\n",
    "            self.topK_shape += ((k_num, 1),)\n",
    "\n",
    "        self.topKv2 = P.TopK(sorted=True)\n",
    "        self.topK_shape_stage2 = (self.max_num, 1)\n",
    "        self.min_float_num = -65536.0\n",
    "        self.topK_mask = Tensor(self.min_float_num * np.ones(total_max_topk_input, self.np_cast_type))\n",
    "\n",
    "    def construct(self, rpn_cls_score_total, rpn_bbox_pred_total, anchor_list):\n",
    "        proposals_tuple = ()\n",
    "        masks_tuple = ()\n",
    "        for img_id in range(self.batch_size):\n",
    "            cls_score_list = ()\n",
    "            bbox_pred_list = ()\n",
    "            for i in range(self.num_levels):\n",
    "                rpn_cls_score_i = self.squeeze(rpn_cls_score_total[i][img_id:img_id + 1:1, ::, ::, ::])\n",
    "                rpn_bbox_pred_i = self.squeeze(rpn_bbox_pred_total[i][img_id:img_id + 1:1, ::, ::, ::])\n",
    "\n",
    "                cls_score_list = cls_score_list + (rpn_cls_score_i,)\n",
    "                bbox_pred_list = bbox_pred_list + (rpn_bbox_pred_i,)\n",
    "\n",
    "            proposals, masks = self.get_bboxes_single(cls_score_list, bbox_pred_list, anchor_list)\n",
    "            proposals_tuple += (proposals,)\n",
    "            masks_tuple += (masks,)\n",
    "        return proposals_tuple, masks_tuple\n",
    "\n",
    "    def get_bboxes_single(self, cls_scores, bbox_preds, mlvl_anchors):\n",
    "        \"\"\"Get proposal boundingbox.\"\"\"\n",
    "        mlvl_proposals = ()\n",
    "        mlvl_mask = ()\n",
    "        for idx in range(self.num_levels):\n",
    "            rpn_cls_score = self.transpose(cls_scores[idx], self.transpose_shape)\n",
    "            rpn_bbox_pred = self.transpose(bbox_preds[idx], self.transpose_shape)\n",
    "            anchors = mlvl_anchors[idx]\n",
    "\n",
    "            rpn_cls_score = self.reshape(rpn_cls_score, self.reshape_shape)\n",
    "            rpn_cls_score = self.activation(rpn_cls_score)\n",
    "            rpn_cls_score_process = self.cast(self.squeeze(rpn_cls_score[::, 0::]), self.cast_type)\n",
    "\n",
    "            rpn_bbox_pred_process = self.cast(self.reshape(rpn_bbox_pred, (-1, 4)), self.cast_type)\n",
    "\n",
    "            scores_sorted, topk_inds = self.topKv2(rpn_cls_score_process, self.topK_stage1[idx])\n",
    "\n",
    "            topk_inds = self.reshape(topk_inds, self.topK_shape[idx])\n",
    "\n",
    "            bboxes_sorted = self.gatherND(rpn_bbox_pred_process, topk_inds)\n",
    "            anchors_sorted = self.cast(self.gatherND(anchors, topk_inds), self.cast_type)\n",
    "\n",
    "            proposals_decode = self.decode(anchors_sorted, bboxes_sorted)\n",
    "\n",
    "            proposals_decode = self.concat_axis1((proposals_decode, self.reshape(scores_sorted, self.topK_shape[idx])))\n",
    "            proposals, _, mask_valid = self.nms(proposals_decode)\n",
    "\n",
    "            mlvl_proposals = mlvl_proposals + (proposals,)\n",
    "            mlvl_mask = mlvl_mask + (mask_valid,)\n",
    "\n",
    "        proposals = self.concat_axis0(mlvl_proposals)\n",
    "        masks = self.concat_axis0(mlvl_mask)\n",
    "\n",
    "        _, _, _, _, scores = self.split(proposals)\n",
    "        scores = self.squeeze(scores)\n",
    "        topk_mask = self.cast(self.topK_mask, self.cast_type)\n",
    "        scores_using = self.select(masks, scores, topk_mask)\n",
    "\n",
    "        _, topk_inds = self.topKv2(scores_using, self.max_num)\n",
    "\n",
    "        topk_inds = self.reshape(topk_inds, self.topK_shape_stage2)\n",
    "        proposals = self.gatherND(proposals, topk_inds)\n",
    "        masks = self.gatherND(masks, topk_inds)\n",
    "        return proposals, masks\n",
    "\n",
    "\n",
    "class BboxAssignSampleForRcnn(nn.Cell):\n",
    "    \"\"\"\n",
    "    Bbox assigner and sampler definition.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Config.\n",
    "        batch_size (int): Batchsize.\n",
    "        num_bboxes (int): The anchor nums.\n",
    "        add_gt_as_proposals (bool): add gt bboxes as proposals flag.\n",
    "\n",
    "    Returns:\n",
    "        Tensor, multiple output tensors.\n",
    "\n",
    "    Examples:\n",
    "        BboxAssignSampleForRcnn(config, 2, 1024, True)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, batch_size, num_bboxes, add_gt_as_proposals):\n",
    "        super(BboxAssignSampleForRcnn, self).__init__()\n",
    "        cfg = config\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.neg_iou_thr = cfg.neg_iou_thr_stage2\n",
    "        self.pos_iou_thr = cfg.pos_iou_thr_stage2\n",
    "        self.min_pos_iou = cfg.min_pos_iou_stage2\n",
    "        self.num_gts = cfg.num_gts\n",
    "        self.num_bboxes = num_bboxes\n",
    "        self.num_expected_pos = cfg.num_expected_pos_stage2\n",
    "        self.num_expected_neg = cfg.num_expected_neg_stage2\n",
    "        self.num_expected_total = cfg.num_expected_total_stage2\n",
    "\n",
    "        self.add_gt_as_proposals = add_gt_as_proposals\n",
    "        self.label_inds = Tensor(np.arange(1, self.num_gts + 1).astype(np.int32))\n",
    "        self.add_gt_as_proposals_valid = Tensor(np.array(self.add_gt_as_proposals * np.ones(self.num_gts),\n",
    "                                                         dtype=np.int32))\n",
    "\n",
    "        self.concat = P.Concat(axis=0)\n",
    "        self.max_gt = P.ArgMaxWithValue(axis=0)\n",
    "        self.max_anchor = P.ArgMaxWithValue(axis=1)\n",
    "        self.sum_inds = P.ReduceSum()\n",
    "        self.iou = P.IOU()\n",
    "        self.greaterequal = P.GreaterEqual()\n",
    "        self.greater = P.Greater()\n",
    "        self.select = P.Select()\n",
    "        self.gatherND = P.GatherNd()\n",
    "        self.squeeze = P.Squeeze()\n",
    "        self.cast = P.Cast()\n",
    "        self.logicaland = P.LogicalAnd()\n",
    "        self.less = P.Less()\n",
    "        self.random_choice_with_mask_pos = P.RandomChoiceWithMask(self.num_expected_pos)\n",
    "        self.random_choice_with_mask_neg = P.RandomChoiceWithMask(self.num_expected_neg)\n",
    "        self.reshape = P.Reshape()\n",
    "        self.equal = P.Equal()\n",
    "        self.bounding_box_encode = P.BoundingBoxEncode(means=(0.0, 0.0, 0.0, 0.0), stds=(0.1, 0.1, 0.2, 0.2))\n",
    "        self.concat_axis1 = P.Concat(axis=1)\n",
    "        self.logicalnot = P.LogicalNot()\n",
    "        self.tile = P.Tile()\n",
    "\n",
    "        # Check\n",
    "        self.check_gt_one = Tensor(np.array(-1 * np.ones((self.num_gts, 4)), dtype=self.np_cast_type))\n",
    "        self.check_anchor_two = Tensor(np.array(-2 * np.ones((self.num_bboxes, 4)), dtype=self.np_cast_type))\n",
    "\n",
    "        # Init tensor\n",
    "        self.assigned_gt_inds = Tensor(np.array(-1 * np.ones(num_bboxes), dtype=np.int32))\n",
    "        self.assigned_gt_zeros = Tensor(np.array(np.zeros(num_bboxes), dtype=np.int32))\n",
    "        self.assigned_gt_ones = Tensor(np.array(np.ones(num_bboxes), dtype=np.int32))\n",
    "        self.assigned_gt_ignores = Tensor(np.array(-1 * np.ones(num_bboxes), dtype=np.int32))\n",
    "        self.assigned_pos_ones = Tensor(np.array(np.ones(self.num_expected_pos), dtype=np.int32))\n",
    "\n",
    "        self.gt_ignores = Tensor(np.array(-1 * np.ones(self.num_gts), dtype=np.int32))\n",
    "        self.range_pos_size = Tensor(np.arange(self.num_expected_pos).astype(self.np_cast_type))\n",
    "        self.check_neg_mask = Tensor(np.array(np.ones(self.num_expected_neg - self.num_expected_pos), dtype=bool))\n",
    "        self.bboxs_neg_mask = Tensor(np.zeros((self.num_expected_neg, 4), dtype=self.np_cast_type))\n",
    "        self.labels_neg_mask = Tensor(np.array(np.zeros(self.num_expected_neg), dtype=np.uint8))\n",
    "\n",
    "        self.reshape_shape_pos = (self.num_expected_pos, 1)\n",
    "        self.reshape_shape_neg = (self.num_expected_neg, 1)\n",
    "\n",
    "        self.scalar_zero = Tensor(0.0, dtype=self.cast_type)\n",
    "        self.scalar_neg_iou_thr = Tensor(self.neg_iou_thr, dtype=self.cast_type)\n",
    "        self.scalar_pos_iou_thr = Tensor(self.pos_iou_thr, dtype=self.cast_type)\n",
    "        self.scalar_min_pos_iou = Tensor(self.min_pos_iou, dtype=self.cast_type)\n",
    "\n",
    "        self.expand_dims = P.ExpandDims()\n",
    "        self.split = P.Split(axis=1, output_num=4)\n",
    "        self.concat_last_axis = P.Concat(axis=-1)\n",
    "        self.round = P.Round()\n",
    "        self.image_h_w = Tensor([cfg.img_height, cfg.img_width, cfg.img_height, cfg.img_width], dtype=self.cast_type)\n",
    "        self.range = nn.Range(start=0, limit=cfg.num_expected_pos_stage2)\n",
    "        self.crop_and_resize = P.CropAndResize(method=\"bilinear_v2\")\n",
    "        self.mask_shape = (cfg.mask_shape[0], cfg.mask_shape[1])\n",
    "        self.squeeze_mask_last = P.Squeeze(axis=-1)\n",
    "\n",
    "    def construct(self, gt_bboxes_i, gt_labels_i, valid_mask, bboxes, gt_valids, gt_masks_i):\n",
    "        gt_bboxes_i = self.select(self.cast(self.tile(self.reshape(self.cast(gt_valids, mstype.int32), \\\n",
    "                                                                   (self.num_gts, 1)), (1, 4)), mstype.bool_), \\\n",
    "                                  gt_bboxes_i, self.check_gt_one)\n",
    "        bboxes = self.select(self.cast(self.tile(self.reshape(self.cast(valid_mask, mstype.int32), \\\n",
    "                                                              (self.num_bboxes, 1)), (1, 4)), mstype.bool_), \\\n",
    "                             bboxes, self.check_anchor_two)\n",
    "\n",
    "        overlaps = self.iou(bboxes, gt_bboxes_i)\n",
    "\n",
    "        max_overlaps_w_gt_index, max_overlaps_w_gt = self.max_gt(overlaps)\n",
    "        _, max_overlaps_w_ac = self.max_anchor(overlaps)\n",
    "\n",
    "        neg_sample_iou_mask = self.logicaland(self.greaterequal(max_overlaps_w_gt,\n",
    "                                                                self.scalar_zero),\n",
    "                                              self.less(max_overlaps_w_gt,\n",
    "                                                        self.scalar_neg_iou_thr))\n",
    "\n",
    "        assigned_gt_inds2 = self.select(neg_sample_iou_mask, self.assigned_gt_zeros, self.assigned_gt_inds)\n",
    "\n",
    "        pos_sample_iou_mask = self.greaterequal(max_overlaps_w_gt, self.scalar_pos_iou_thr)\n",
    "        assigned_gt_inds3 = self.select(pos_sample_iou_mask, \\\n",
    "                                        max_overlaps_w_gt_index + self.assigned_gt_ones, assigned_gt_inds2)\n",
    "\n",
    "        for j in range(self.num_gts):\n",
    "            max_overlaps_w_ac_j = max_overlaps_w_ac[j:j + 1:1]\n",
    "            overlaps_w_ac_j = overlaps[j:j + 1:1, ::]\n",
    "            temp1 = self.greaterequal(max_overlaps_w_ac_j, self.scalar_min_pos_iou)\n",
    "            temp2 = self.squeeze(self.equal(overlaps_w_ac_j, max_overlaps_w_ac_j))\n",
    "            pos_mask_j = self.logicaland(temp1, temp2)\n",
    "            assigned_gt_inds3 = self.select(pos_mask_j, (j + 1) * self.assigned_gt_ones, assigned_gt_inds3)\n",
    "\n",
    "        assigned_gt_inds5 = self.select(valid_mask, assigned_gt_inds3, self.assigned_gt_ignores)\n",
    "\n",
    "        bboxes = self.concat((gt_bboxes_i, bboxes))\n",
    "        label_inds_valid = self.select(gt_valids, self.label_inds, self.gt_ignores)\n",
    "        label_inds_valid = label_inds_valid * self.add_gt_as_proposals_valid\n",
    "        assigned_gt_inds5 = self.concat((label_inds_valid, assigned_gt_inds5))\n",
    "\n",
    "        # Get pos index\n",
    "        pos_index, valid_pos_index = self.random_choice_with_mask_pos(self.greater(assigned_gt_inds5, 0))\n",
    "\n",
    "        pos_check_valid = self.cast(self.greater(assigned_gt_inds5, 0), self.cast_type)\n",
    "        pos_check_valid = self.sum_inds(pos_check_valid, -1)\n",
    "        valid_pos_index = self.less(self.range_pos_size, pos_check_valid)\n",
    "        pos_index = pos_index * self.reshape(self.cast(valid_pos_index, mstype.int32), (self.num_expected_pos, 1))\n",
    "\n",
    "        num_pos = self.sum_inds(self.cast(self.logicalnot(valid_pos_index), self.cast_type), -1)\n",
    "        valid_pos_index = self.cast(valid_pos_index, mstype.int32)\n",
    "        pos_index = self.reshape(pos_index, self.reshape_shape_pos)\n",
    "        valid_pos_index = self.reshape(valid_pos_index, self.reshape_shape_pos)\n",
    "        pos_index = pos_index * valid_pos_index\n",
    "\n",
    "        pos_assigned_gt_index = self.gatherND(assigned_gt_inds5, pos_index) - self.assigned_pos_ones\n",
    "        pos_assigned_gt_index = self.reshape(pos_assigned_gt_index, self.reshape_shape_pos)\n",
    "        pos_assigned_gt_index = pos_assigned_gt_index * valid_pos_index\n",
    "\n",
    "        pos_gt_labels = self.gatherND(gt_labels_i, pos_assigned_gt_index)\n",
    "\n",
    "        # Get neg index\n",
    "        neg_index, valid_neg_index = self.random_choice_with_mask_neg(self.equal(assigned_gt_inds5, 0))\n",
    "\n",
    "        unvalid_pos_index = self.less(self.range_pos_size, num_pos)\n",
    "        valid_neg_index = self.logicaland(self.concat((self.check_neg_mask, unvalid_pos_index)), valid_neg_index)\n",
    "        neg_index = self.reshape(neg_index, self.reshape_shape_neg)\n",
    "\n",
    "        valid_neg_index = self.cast(valid_neg_index, mstype.int32)\n",
    "        valid_neg_index = self.reshape(valid_neg_index, self.reshape_shape_neg)\n",
    "        neg_index = neg_index * valid_neg_index\n",
    "\n",
    "        pos_bboxes_ = self.gatherND(bboxes, pos_index)\n",
    "\n",
    "        neg_bboxes_ = self.gatherND(bboxes, neg_index)\n",
    "        pos_assigned_gt_index = self.reshape(pos_assigned_gt_index, self.reshape_shape_pos)\n",
    "        pos_gt_bboxes_ = self.gatherND(gt_bboxes_i, pos_assigned_gt_index)\n",
    "        pos_bbox_targets_ = self.bounding_box_encode(pos_bboxes_, pos_gt_bboxes_)\n",
    "\n",
    "        # assign positive ROIs to gt masks\n",
    "        # Pick the right front and background mask for each ROI\n",
    "        roi_pos_masks_fb = self.gatherND(gt_masks_i, pos_assigned_gt_index)\n",
    "        pos_masks_fb = self.cast(roi_pos_masks_fb, mstype.float32)\n",
    "        # compute mask targets\n",
    "        x1, y1, x2, y2 = self.split(pos_bboxes_)\n",
    "        boxes = self.concat_last_axis((y1, x1, y2, x2))\n",
    "        # normalized box coordinate\n",
    "        boxes = boxes / self.image_h_w\n",
    "        box_ids = self.range()\n",
    "        pos_masks_fb = self.expand_dims(pos_masks_fb, -1)\n",
    "        boxes = self.cast(boxes, mstype.float32)\n",
    "        pos_masks_fb = self.crop_and_resize(pos_masks_fb, boxes, box_ids, self.mask_shape)\n",
    "\n",
    "        # Remove the extra dimension from masks.\n",
    "        pos_masks_fb = self.squeeze_mask_last(pos_masks_fb)\n",
    "\n",
    "        # convert gt masks targets be 0 or 1 to use with binary cross entropy loss.\n",
    "        pos_masks_fb = self.round(pos_masks_fb)\n",
    "\n",
    "        pos_masks_fb = self.cast(pos_masks_fb, self.cast_type)\n",
    "        total_bboxes = self.concat((pos_bboxes_, neg_bboxes_))\n",
    "        total_deltas = self.concat((pos_bbox_targets_, self.bboxs_neg_mask))\n",
    "        total_labels = self.concat((pos_gt_labels, self.labels_neg_mask))\n",
    "\n",
    "        valid_pos_index = self.reshape(valid_pos_index, self.reshape_shape_pos)\n",
    "        valid_neg_index = self.reshape(valid_neg_index, self.reshape_shape_neg)\n",
    "        total_mask = self.concat((valid_pos_index, valid_neg_index))\n",
    "\n",
    "        return total_bboxes, total_deltas, total_labels, total_mask, pos_bboxes_, pos_masks_fb, \\\n",
    "               pos_gt_labels, valid_pos_index\n",
    "\n",
    "\n",
    "class DenseNoTranpose(nn.Cell):\n",
    "    \"\"\"Dense method\"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, output_channels, weight_init):\n",
    "        super(DenseNoTranpose, self).__init__()\n",
    "        self.weight = Parameter(initializer(weight_init, [input_channels, output_channels], mstype.float32))\n",
    "        self.bias = Parameter(initializer(\"zeros\", [output_channels], mstype.float32))\n",
    "        self.matmul = P.MatMul(transpose_b=False)\n",
    "        self.bias_add = P.BiasAdd()\n",
    "\n",
    "    def construct(self, x):\n",
    "        output = self.bias_add(self.matmul(x, self.weight), self.bias)\n",
    "        return output\n",
    "\n",
    "\n",
    "class FpnCls(nn.Cell):\n",
    "    \"\"\"dense layer of classification and box head\"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, output_channels, num_classes, pool_size):\n",
    "        super(FpnCls, self).__init__()\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "\n",
    "        representation_size = input_channels * pool_size * pool_size\n",
    "        shape_0 = (output_channels, representation_size)\n",
    "        weights_0 = initializer(\"XavierUniform\", shape=shape_0[::-1], dtype=mstype.float32)\n",
    "        shape_1 = (output_channels, output_channels)\n",
    "        weights_1 = initializer(\"XavierUniform\", shape=shape_1[::-1], dtype=mstype.float32)\n",
    "        self.shared_fc_0 = DenseNoTranpose(representation_size, output_channels, weights_0).to_float(self.cast_type)\n",
    "        self.shared_fc_1 = DenseNoTranpose(output_channels, output_channels, weights_1).to_float(self.cast_type)\n",
    "\n",
    "        cls_weight = initializer('Normal', shape=[num_classes, output_channels][::-1],\n",
    "                                 dtype=mstype.float32)\n",
    "        reg_weight = initializer('Normal', shape=[num_classes * 4, output_channels][::-1],\n",
    "                                 dtype=mstype.float32)\n",
    "        self.cls_scores = DenseNoTranpose(output_channels, num_classes, cls_weight).to_float(self.cast_type)\n",
    "        self.reg_scores = DenseNoTranpose(output_channels, num_classes * 4, reg_weight).to_float(self.cast_type)\n",
    "\n",
    "        self.relu = P.ReLU()\n",
    "        self.flatten = P.Flatten()\n",
    "\n",
    "    def construct(self, x):\n",
    "        # two share fc layer\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x = self.relu(self.shared_fc_0(x))\n",
    "        x = self.relu(self.shared_fc_1(x))\n",
    "\n",
    "        # classifier head\n",
    "        cls_scores = self.cls_scores(x)\n",
    "        # bbox head\n",
    "        reg_scores = self.reg_scores(x)\n",
    "\n",
    "        return cls_scores, reg_scores\n",
    "\n",
    "\n",
    "class RcnnCls(nn.Cell):\n",
    "    \"\"\"\n",
    "    Rcnn for classification and box regression subnet.\n",
    "\n",
    "    Args:\n",
    "        config (dict) - Config.\n",
    "        batch_size (int) - Batchsize.\n",
    "        num_classes (int) - Class number.\n",
    "        target_means (list) - Means for encode function. Default: (.0, .0, .0, .0]).\n",
    "        target_stds (list) - Stds for encode function. Default: (0.1, 0.1, 0.2, 0.2).\n",
    "\n",
    "    Returns:\n",
    "        Tuple, tuple of output tensor.\n",
    "\n",
    "    Examples:\n",
    "        RcnnCls(config=config, representation_size = 1024, batch_size=2, num_classes = 81, \\\n",
    "             target_means=(0., 0., 0., 0.), target_stds=(0.1, 0.1, 0.2, 0.2))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 batch_size,\n",
    "                 num_classes,\n",
    "                 target_means=(0., 0., 0., 0.),\n",
    "                 target_stds=(0.1, 0.1, 0.2, 0.2)\n",
    "                 ):\n",
    "        super(RcnnCls, self).__init__()\n",
    "        cfg = config\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "\n",
    "        self.rcnn_loss_cls_weight = Tensor(np.array(cfg.rcnn_loss_cls_weight).astype(self.np_cast_type))\n",
    "        self.rcnn_loss_reg_weight = Tensor(np.array(cfg.rcnn_loss_reg_weight).astype(self.np_cast_type))\n",
    "        self.rcnn_fc_out_channels = cfg.rcnn_fc_out_channels\n",
    "        self.target_means = target_means\n",
    "        self.target_stds = target_stds\n",
    "        self.num_classes = num_classes\n",
    "        self.in_channels = cfg.rcnn_in_channels\n",
    "        self.train_batch_size = batch_size\n",
    "        self.test_batch_size = cfg.test_batch_size\n",
    "\n",
    "        self.fpn_cls = FpnCls(self.in_channels, self.rcnn_fc_out_channels, self.num_classes, cfg.roi_layer.out_size)\n",
    "        self.relu = P.ReLU()\n",
    "        self.logicaland = P.LogicalAnd()\n",
    "        self.loss_cls = P.SoftmaxCrossEntropyWithLogits()\n",
    "        self.loss_bbox = P.SmoothL1Loss(beta=1.0)\n",
    "        self.loss_mask = P.SigmoidCrossEntropyWithLogits()\n",
    "        self.reshape = P.Reshape()\n",
    "        self.onehot = P.OneHot()\n",
    "        self.greater = P.Greater()\n",
    "        self.cast = P.Cast()\n",
    "        self.sum_loss = P.ReduceSum()\n",
    "        self.tile = P.Tile()\n",
    "        self.expandims = P.ExpandDims()\n",
    "\n",
    "        self.gather = P.GatherNd()\n",
    "        self.argmax = P.ArgMaxWithValue(axis=1)\n",
    "\n",
    "        self.on_value = Tensor(1.0, mstype.float32)\n",
    "        self.off_value = Tensor(0.0, mstype.float32)\n",
    "        self.value = Tensor(1.0, self.cast_type)\n",
    "\n",
    "        self.num_bboxes = (cfg.num_expected_pos_stage2 + cfg.num_expected_neg_stage2) * batch_size\n",
    "\n",
    "        rmv_first = np.ones((self.num_bboxes, self.num_classes))\n",
    "        rmv_first[:, 0] = np.zeros((self.num_bboxes,))\n",
    "        self.rmv_first_tensor = Tensor(rmv_first.astype(self.np_cast_type))\n",
    "\n",
    "        self.num_bboxes_test = cfg.rpn_max_num * cfg.test_batch_size\n",
    "\n",
    "    def construct(self, featuremap, bbox_targets, labels, mask):\n",
    "        x_cls, x_reg = self.fpn_cls(featuremap)\n",
    "\n",
    "        if self.training:\n",
    "            bbox_weights = self.cast(self.logicaland(self.greater(labels, 0), mask), mstype.int32) * labels\n",
    "            labels = self.cast(self.onehot(labels, self.num_classes, self.on_value, self.off_value), self.cast_type)\n",
    "            bbox_targets = self.tile(self.expandims(bbox_targets, 1), (1, self.num_classes, 1))\n",
    "\n",
    "            loss_cls, loss_reg = self.loss(x_cls, x_reg,\n",
    "                                           bbox_targets, bbox_weights,\n",
    "                                           labels,\n",
    "                                           mask)\n",
    "            out = (loss_cls, loss_reg)\n",
    "        else:\n",
    "            out = (x_cls, x_reg)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def loss(self, cls_score, bbox_pred, bbox_targets, bbox_weights, labels, weights):\n",
    "        \"\"\"Loss method.\"\"\"\n",
    "        # loss_cls\n",
    "        loss_cls, _ = self.loss_cls(cls_score, labels)\n",
    "        weights = self.cast(weights, self.cast_type)\n",
    "        loss_cls = loss_cls * weights\n",
    "        loss_cls = self.sum_loss(loss_cls, (0,)) / (self.sum_loss(weights, (0,)) + 1e-5)\n",
    "\n",
    "        # loss_reg\n",
    "        bbox_weights = self.cast(self.onehot(bbox_weights, self.num_classes, self.on_value, self.off_value),\n",
    "                                 self.cast_type)\n",
    "        bbox_weights = bbox_weights * self.rmv_first_tensor  # * self.rmv_first_tensor  exclude background\n",
    "        pos_bbox_pred = self.reshape(bbox_pred, (self.num_bboxes, -1, 4))\n",
    "        loss_reg = self.loss_bbox(pos_bbox_pred, bbox_targets)\n",
    "        loss_reg = self.sum_loss(loss_reg, (2,))\n",
    "        loss_reg = loss_reg * bbox_weights\n",
    "        loss_reg = loss_reg / (self.sum_loss(weights, (0,)) + 1e-5)\n",
    "        loss_reg = self.sum_loss(loss_reg, (0, 1))\n",
    "\n",
    "        return loss_cls, loss_reg\n",
    "\n",
    "\n",
    "class FpnMask(nn.Cell):\n",
    "    \"\"\"conv layers of mask head\"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, output_channels, num_classes):\n",
    "        super(FpnMask, self).__init__()\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "\n",
    "        self.mask_conv1 = nn.Conv2d(input_channels, output_channels, kernel_size=3,\n",
    "                                    pad_mode=\"same\").to_float(self.cast_type)\n",
    "        self.mask_relu1 = P.ReLU()\n",
    "\n",
    "        self.mask_conv2 = nn.Conv2d(output_channels, output_channels, kernel_size=3,\n",
    "                                    pad_mode=\"same\").to_float(self.cast_type)\n",
    "        self.mask_relu2 = P.ReLU()\n",
    "\n",
    "        self.mask_conv3 = nn.Conv2d(output_channels, output_channels, kernel_size=3,\n",
    "                                    pad_mode=\"same\").to_float(self.cast_type)\n",
    "        self.mask_relu3 = P.ReLU()\n",
    "\n",
    "        self.mask_conv4 = nn.Conv2d(output_channels, output_channels, kernel_size=3,\n",
    "                                    pad_mode=\"same\").to_float(self.cast_type)\n",
    "        self.mask_relu4 = P.ReLU()\n",
    "\n",
    "        self.mask_deconv5 = nn.Conv2dTranspose(output_channels, output_channels, kernel_size=2,\n",
    "                                               stride=2, pad_mode=\"valid\").to_float(self.cast_type)\n",
    "        self.mask_relu5 = P.ReLU()\n",
    "        self.mask_conv6 = nn.Conv2d(output_channels, num_classes, kernel_size=1, stride=1,\n",
    "                                    pad_mode=\"valid\").to_float(self.cast_type)\n",
    "\n",
    "    def construct(self, x):\n",
    "        x = self.mask_conv1(x)\n",
    "        x = self.mask_relu1(x)\n",
    "\n",
    "        x = self.mask_conv2(x)\n",
    "        x = self.mask_relu2(x)\n",
    "\n",
    "        x = self.mask_conv3(x)\n",
    "        x = self.mask_relu3(x)\n",
    "\n",
    "        x = self.mask_conv4(x)\n",
    "        x = self.mask_relu4(x)\n",
    "\n",
    "        x = self.mask_deconv5(x)\n",
    "        x = self.mask_relu5(x)\n",
    "\n",
    "        x = self.mask_conv6(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class RcnnMask(nn.Cell):\n",
    "    \"\"\"\n",
    "    Rcnn for mask subnet.\n",
    "\n",
    "    Args:\n",
    "        config (dict) - Config.\n",
    "        batch_size (int) - Batchsize.\n",
    "        num_classes (int) - Class number.\n",
    "        target_means (list) - Means for encode function. Default: (.0, .0, .0, .0]).\n",
    "        target_stds (list) - Stds for encode function. Default: (0.1, 0.1, 0.2, 0.2).\n",
    "\n",
    "    Returns:\n",
    "        Tuple, tuple of output tensor.\n",
    "\n",
    "    Examples:\n",
    "        RcnnMask(config=config, representation_size = 1024, batch_size=2, num_classes = 81, \\\n",
    "             target_means=(0., 0., 0., 0.), target_stds=(0.1, 0.1, 0.2, 0.2))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 batch_size,\n",
    "                 num_classes,\n",
    "                 target_means=(0., 0., 0., 0.),\n",
    "                 target_stds=(0.1, 0.1, 0.2, 0.2)\n",
    "                 ):\n",
    "        super(RcnnMask, self).__init__()\n",
    "        cfg = config\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "\n",
    "        self.rcnn_loss_mask_fb_weight = Tensor(np.array(cfg.rcnn_loss_mask_fb_weight).astype(self.np_cast_type))\n",
    "        self.rcnn_mask_out_channels = cfg.rcnn_mask_out_channels\n",
    "        self.target_means = target_means\n",
    "        self.target_stds = target_stds\n",
    "        self.num_classes = num_classes\n",
    "        self.in_channels = cfg.rcnn_in_channels\n",
    "\n",
    "        self.fpn_mask = FpnMask(self.in_channels, self.rcnn_mask_out_channels, self.num_classes)\n",
    "\n",
    "        self.logicaland = P.LogicalAnd()\n",
    "        self.loss_mask = P.SigmoidCrossEntropyWithLogits()\n",
    "        self.onehot = P.OneHot()\n",
    "        self.greater = P.Greater()\n",
    "        self.cast = P.Cast()\n",
    "        self.sum_loss = P.ReduceSum()\n",
    "        self.tile = P.Tile()\n",
    "        self.expandims = P.ExpandDims()\n",
    "\n",
    "        self.on_value = Tensor(1.0, mstype.float32)\n",
    "        self.off_value = Tensor(0.0, mstype.float32)\n",
    "\n",
    "        self.num_bboxes = cfg.num_expected_pos_stage2 * batch_size\n",
    "        rmv_first = np.ones((self.num_bboxes, self.num_classes))\n",
    "        rmv_first[:, 0] = np.zeros((self.num_bboxes,))\n",
    "        self.rmv_first_tensor = Tensor(rmv_first.astype(self.np_cast_type))\n",
    "        self.mean_loss = P.ReduceMean()\n",
    "\n",
    "    def construct(self, mask_featuremap, labels=None, mask=None, mask_fb_targets=None):\n",
    "        x_mask_fb = self.fpn_mask(mask_featuremap)\n",
    "\n",
    "        if self.training:\n",
    "            bbox_weights = self.cast(self.logicaland(self.greater(labels, 0), mask), mstype.int32) * labels\n",
    "            mask_fb_targets = self.tile(self.expandims(mask_fb_targets, 1), (1, self.num_classes, 1, 1))\n",
    "\n",
    "            loss_mask_fb = self.loss(x_mask_fb, bbox_weights, mask, mask_fb_targets)\n",
    "            out = loss_mask_fb\n",
    "        else:\n",
    "            out = x_mask_fb\n",
    "\n",
    "        return out\n",
    "\n",
    "    def loss(self, masks_fb_pred, bbox_weights, weights, masks_fb_targets):\n",
    "        \"\"\"Loss method.\"\"\"\n",
    "        weights = self.cast(weights, self.cast_type)\n",
    "        bbox_weights = self.cast(self.onehot(bbox_weights, self.num_classes, self.on_value, self.off_value),\n",
    "                                 self.cast_type)\n",
    "        bbox_weights = bbox_weights * self.rmv_first_tensor  # * self.rmv_first_tensor  exclude background\n",
    "\n",
    "        # loss_mask_fb\n",
    "        masks_fb_targets = self.cast(masks_fb_targets, self.cast_type)\n",
    "        loss_mask_fb = self.loss_mask(masks_fb_pred, masks_fb_targets)\n",
    "        loss_mask_fb = self.mean_loss(loss_mask_fb, (2, 3))\n",
    "        loss_mask_fb = loss_mask_fb * bbox_weights\n",
    "        loss_mask_fb = loss_mask_fb / (self.sum_loss(weights, (0,)) + 1e-5)\n",
    "        loss_mask_fb = self.sum_loss(loss_mask_fb, (0, 1))\n",
    "\n",
    "        return loss_mask_fb\n",
    "\n",
    "\n",
    "class AnchorGenerator():\n",
    "    \"\"\"Anchor generator for MasKRcnn.\"\"\"\n",
    "    def __init__(self, base_size, scales, ratios, scale_major=True, ctr=None):\n",
    "        \"\"\"Anchor generator init method.\"\"\"\n",
    "        self.base_size = base_size\n",
    "        self.scales = np.array(scales)\n",
    "        self.ratios = np.array(ratios)\n",
    "        self.scale_major = scale_major\n",
    "        self.ctr = ctr\n",
    "        self.base_anchors = self.gen_base_anchors()\n",
    "\n",
    "    def gen_base_anchors(self):\n",
    "        \"\"\"Generate a single anchor.\"\"\"\n",
    "        w = self.base_size\n",
    "        h = self.base_size\n",
    "        if self.ctr is None:\n",
    "            x_ctr = 0.5 * (w - 1)\n",
    "            y_ctr = 0.5 * (h - 1)\n",
    "        else:\n",
    "            x_ctr, y_ctr = self.ctr\n",
    "\n",
    "        h_ratios = np.sqrt(self.ratios)\n",
    "        w_ratios = 1 / h_ratios\n",
    "        if self.scale_major:\n",
    "            ws = (w * w_ratios[:, None] * self.scales[None, :]).reshape(-1)\n",
    "            hs = (h * h_ratios[:, None] * self.scales[None, :]).reshape(-1)\n",
    "        else:\n",
    "            ws = (w * self.scales[:, None] * w_ratios[None, :]).reshape(-1)\n",
    "            hs = (h * self.scales[:, None] * h_ratios[None, :]).reshape(-1)\n",
    "\n",
    "        base_anchors = np.stack(\n",
    "            [\n",
    "                x_ctr - 0.5 * (ws - 1), y_ctr - 0.5 * (hs - 1),\n",
    "                x_ctr + 0.5 * (ws - 1), y_ctr + 0.5 * (hs - 1)\n",
    "            ],\n",
    "            axis=-1).round()\n",
    "\n",
    "        return base_anchors\n",
    "\n",
    "    def _meshgrid(self, x, y, row_major=True):\n",
    "        \"\"\"Generate grid.\"\"\"\n",
    "        xx = np.repeat(x.reshape(1, len(x)), len(y), axis=0).reshape(-1)\n",
    "        yy = np.repeat(y, len(x))\n",
    "        if row_major:\n",
    "            return xx, yy\n",
    "\n",
    "        return yy, xx\n",
    "\n",
    "    def grid_anchors(self, featmap_size, stride=16):\n",
    "        \"\"\"Generate anchor list.\"\"\"\n",
    "        base_anchors = self.base_anchors\n",
    "\n",
    "        feat_h, feat_w = featmap_size\n",
    "        shift_x = np.arange(0, feat_w) * stride\n",
    "        shift_y = np.arange(0, feat_h) * stride\n",
    "        shift_xx, shift_yy = self._meshgrid(shift_x, shift_y)\n",
    "        shifts = np.stack([shift_xx, shift_yy, shift_xx, shift_yy], axis=-1)\n",
    "        shifts = shifts.astype(base_anchors.dtype)\n",
    "        # first feat_w elements correspond to the first row of shifts\n",
    "        # add A anchors (1, A, 4) to K shifts (K, 1, 4) to get\n",
    "        # shifted anchors (K, A, 4), reshape to (K*A, 4)\n",
    "\n",
    "        all_anchors = base_anchors[None, :, :] + shifts[:, None, :]\n",
    "        all_anchors = all_anchors.reshape(-1, 4)\n",
    "\n",
    "        return all_anchors\n",
    "\n",
    "\n",
    "class ROIAlign(nn.Cell):\n",
    "    \"\"\"\n",
    "    Extract RoI features from mulitiple feature map.\n",
    "\n",
    "    Args:\n",
    "        out_size_h (int) - RoI height.\n",
    "        out_size_w (int) - RoI width.\n",
    "        spatial_scale (int) - RoI spatial scale.\n",
    "        sample_num (int) - RoI sample number.\n",
    "        roi_align_mode (int)- RoI align mode\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 out_size_h,\n",
    "                 out_size_w,\n",
    "                 spatial_scale,\n",
    "                 sample_num=0,\n",
    "                 roi_align_mode=1):\n",
    "        super(ROIAlign, self).__init__()\n",
    "\n",
    "        self.out_size = (out_size_h, out_size_w)\n",
    "        self.spatial_scale = float(spatial_scale)\n",
    "        self.sample_num = int(sample_num)\n",
    "        self.align_op = P.ROIAlign(self.out_size[0], self.out_size[1],\n",
    "                                   self.spatial_scale, self.sample_num, roi_align_mode)\n",
    "\n",
    "    def construct(self, features, rois):\n",
    "        return self.align_op(features, rois)\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_str = self.__class__.__name__\n",
    "        format_str += '(out_size={}, spatial_scale={}, sample_num={}'.format(\n",
    "            self.out_size, self.spatial_scale, self.sample_num)\n",
    "        return format_str\n",
    "\n",
    "\n",
    "class SingleRoIExtractor(nn.Cell):\n",
    "    \"\"\"\n",
    "    Extract RoI features from a single level feature map.\n",
    "\n",
    "    If there are multiple input feature levels, each RoI is mapped to a level\n",
    "    according to its scale.\n",
    "\n",
    "    Args:\n",
    "        config (dict): Config\n",
    "        roi_layer (dict): Specify RoI layer type and arguments.\n",
    "        out_channels (int): Output channels of RoI layers.\n",
    "        featmap_strides (int): Strides of input feature maps.\n",
    "        batch_size (int) Batchsize.\n",
    "        finest_scale (int): Scale threshold of mapping to level 0.\n",
    "        mask (bool): Specify ROIAlign for cls or mask branch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 roi_layer,\n",
    "                 out_channels,\n",
    "                 featmap_strides,\n",
    "                 batch_size=1,\n",
    "                 finest_scale=56,\n",
    "                 mask=False):\n",
    "        super(SingleRoIExtractor, self).__init__()\n",
    "        cfg = config\n",
    "        self.train_batch_size = batch_size\n",
    "        self.out_channels = out_channels\n",
    "        self.featmap_strides = featmap_strides\n",
    "        self.num_levels = len(self.featmap_strides)\n",
    "        self.out_size = config.roi_layer.mask_out_size if mask else config.roi_layer.out_size\n",
    "        self.mask = mask\n",
    "        self.sample_num = config.roi_layer.sample_num\n",
    "        self.roi_layers = self.build_roi_layers(self.featmap_strides)\n",
    "        self.roi_layers = L.CellList(self.roi_layers)\n",
    "\n",
    "        self.sqrt = P.Sqrt()\n",
    "        self.log = P.Log()\n",
    "        self.finest_scale_ = finest_scale\n",
    "        self.clamp = C.clip_by_value\n",
    "\n",
    "        self.cast = P.Cast()\n",
    "        self.equal = P.Equal()\n",
    "        self.select = P.Select()\n",
    "\n",
    "        _mode_16 = False\n",
    "        self.dtype = np.float16 if _mode_16 else np.float32\n",
    "        self.ms_dtype = mstype.float16 if _mode_16 else mstype.float32\n",
    "        self.set_train_local(cfg, training=True)\n",
    "\n",
    "    def set_train_local(self, config, training=True):\n",
    "        \"\"\"Set training flag.\"\"\"\n",
    "        self.training_local = training\n",
    "\n",
    "        cfg = config\n",
    "        # Init tensor\n",
    "        roi_sample_num = cfg.num_expected_pos_stage2 if self.mask else cfg.roi_sample_num\n",
    "        self.batch_size = roi_sample_num if self.training_local else cfg.rpn_max_num\n",
    "        self.batch_size = self.train_batch_size*self.batch_size \\\n",
    "            if self.training_local else cfg.test_batch_size*self.batch_size\n",
    "        self.ones = Tensor(np.array(np.ones((self.batch_size, 1)), dtype=self.dtype))\n",
    "        finest_scale = np.array(np.ones((self.batch_size, 1)), dtype=self.dtype) * self.finest_scale_\n",
    "        self.finest_scale = Tensor(finest_scale)\n",
    "        self.epslion = Tensor(np.array(np.ones((self.batch_size, 1)), dtype=self.dtype)*self.dtype(1e-6))\n",
    "        self.zeros = Tensor(np.array(np.zeros((self.batch_size, 1)), dtype=np.int32))\n",
    "        self.max_levels = Tensor(np.array(np.ones((self.batch_size, 1)), dtype=np.int32)*(self.num_levels-1))\n",
    "        self.twos = Tensor(np.array(np.ones((self.batch_size, 1)), dtype=self.dtype) * 2)\n",
    "        self.res_ = Tensor(np.array(np.zeros((self.batch_size, self.out_channels,\n",
    "                                              self.out_size, self.out_size)), dtype=self.dtype))\n",
    "    def num_inputs(self):\n",
    "        return len(self.featmap_strides)\n",
    "\n",
    "    def init_weights(self):\n",
    "        pass\n",
    "\n",
    "    def log2(self, value):\n",
    "        return self.log(value) / self.log(self.twos)\n",
    "\n",
    "    def build_roi_layers(self, featmap_strides):\n",
    "        roi_layers = []\n",
    "        for s in featmap_strides:\n",
    "            layer_cls = ROIAlign(self.out_size, self.out_size,\n",
    "                                 spatial_scale=1 / s,\n",
    "                                 sample_num=self.sample_num,\n",
    "                                 roi_align_mode=0)\n",
    "            roi_layers.append(layer_cls)\n",
    "        return roi_layers\n",
    "\n",
    "    def _c_map_roi_levels(self, rois):\n",
    "        \"\"\"Map rois to corresponding feature levels by scales.\n",
    "\n",
    "        - scale < finest_scale * 2: level 0\n",
    "        - finest_scale * 2 <= scale < finest_scale * 4: level 1\n",
    "        - finest_scale * 4 <= scale < finest_scale * 8: level 2\n",
    "        - scale >= finest_scale * 8: level 3\n",
    "\n",
    "        Args:\n",
    "            rois (Tensor): Input RoIs, shape (k, 5).\n",
    "            num_levels (int): Total level number.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Level index (0-based) of each RoI, shape (k, )\n",
    "        \"\"\"\n",
    "        scale = self.sqrt(rois[::, 3:4:1] - rois[::, 1:2:1] + self.ones) * \\\n",
    "             self.sqrt(rois[::, 4:5:1] - rois[::, 2:3:1] + self.ones)\n",
    "\n",
    "        target_lvls = self.log2(scale / self.finest_scale + self.epslion)\n",
    "        target_lvls = P.Floor()(target_lvls)\n",
    "        target_lvls = self.cast(target_lvls, mstype.int32)\n",
    "        target_lvls = self.clamp(target_lvls, self.zeros, self.max_levels)\n",
    "\n",
    "        return target_lvls\n",
    "\n",
    "    def construct(self, rois, feat1, feat2, feat3, feat4):\n",
    "        feats = (feat1, feat2, feat3, feat4)\n",
    "        res = self.res_\n",
    "        target_lvls = self._c_map_roi_levels(rois)\n",
    "        for i in range(self.num_levels):\n",
    "            mask = self.equal(target_lvls, P.ScalarToArray()(i))\n",
    "            mask = P.Reshape()(mask, (-1, 1, 1, 1))\n",
    "            roi_feats_t = self.roi_layers[i](feats[i], rois)\n",
    "            mask = self.cast(P.Tile()(self.cast(mask, mstype.int32), (1, 256, self.out_size, self.out_size)),\n",
    "                             mstype.bool_)\n",
    "            res = self.select(mask, roi_feats_t, res)\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "class MaskRCNN(nn.Cell):\n",
    "    \"\"\"\n",
    "    MaskRcnn Network.\n",
    "\n",
    "    Note:\n",
    "        backbone = resnet50\n",
    "\n",
    "    Returns:\n",
    "        Tuple, tuple of output tensor.\n",
    "        rpn_loss: Scalar, Total loss of RPN subnet.\n",
    "        rcnn_loss: Scalar, Total loss of RCNN subnet.\n",
    "        rpn_cls_loss: Scalar, Classification loss of RPN subnet.\n",
    "        rpn_reg_loss: Scalar, Regression loss of RPN subnet.\n",
    "        rcnn_cls_loss: Scalar, Classification loss of RCNNcls subnet.\n",
    "        rcnn_reg_loss: Scalar, Regression loss of RCNNcls subnet.\n",
    "        rcnn_mask_loss: Scalar, mask loss of RCNNmask subnet.\n",
    "\n",
    "    Examples:\n",
    "        net = Mask_Rcnn_Resnet50()\n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(MaskRCNN, self).__init__()\n",
    "\n",
    "        if context.get_context(\"device_target\") == \"Ascend\":\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "        else:\n",
    "            self.cast_type = mstype.float32\n",
    "            self.np_cast_type = np.float32\n",
    "\n",
    "        self.train_batch_size = config.batch_size\n",
    "        self.num_classes = config.num_classes\n",
    "        self.anchor_scales = config.anchor_scales\n",
    "        self.anchor_ratios = config.anchor_ratios\n",
    "        self.anchor_strides = config.anchor_strides\n",
    "        self.target_means = tuple(config.rcnn_target_means)\n",
    "        self.target_stds = tuple(config.rcnn_target_stds)\n",
    "\n",
    "        # Anchor generator\n",
    "        anchor_base_sizes = None\n",
    "        self.anchor_base_sizes = list(\n",
    "            self.anchor_strides) if anchor_base_sizes is None else anchor_base_sizes\n",
    "\n",
    "        self.anchor_generators = []\n",
    "        for anchor_base in self.anchor_base_sizes:\n",
    "            self.anchor_generators.append(\n",
    "                AnchorGenerator(anchor_base, self.anchor_scales, self.anchor_ratios))\n",
    "\n",
    "        self.num_anchors = len(self.anchor_ratios) * len(self.anchor_scales)\n",
    "\n",
    "        featmap_sizes = config.feature_shapes\n",
    "        assert len(featmap_sizes) == len(self.anchor_generators)\n",
    "\n",
    "        self.anchor_list = self.get_anchors(featmap_sizes)\n",
    "\n",
    "        # Backbone resnet50\n",
    "        self.backbone = ResNet(ResidualBlock,\n",
    "                                  config.resnet_block,\n",
    "                                  config.resnet_in_channels,\n",
    "                                  config.resnet_out_channels,\n",
    "                                  False)\n",
    "\n",
    "        # Fpn\n",
    "        self.fpn_ncek = FeatPyramidNeck(config.fpn_in_channels,\n",
    "                                        config.fpn_out_channels,\n",
    "                                        config.fpn_num_outs,\n",
    "                                        config.feature_shapes)\n",
    "\n",
    "        # Rpn and rpn loss\n",
    "        self.gt_labels_stage1 = Tensor(np.ones((self.train_batch_size, config.num_gts)).astype(np.uint8))\n",
    "        self.rpn_with_loss = RPN(config,\n",
    "                                 self.train_batch_size,\n",
    "                                 config.rpn_in_channels,\n",
    "                                 config.rpn_feat_channels,\n",
    "                                 config.num_anchors,\n",
    "                                 config.rpn_cls_out_channels)\n",
    "\n",
    "        # Proposal\n",
    "        self.proposal_generator = Proposal(config,\n",
    "                                           self.train_batch_size,\n",
    "                                           config.activate_num_classes,\n",
    "                                           config.use_sigmoid_cls)\n",
    "        self.proposal_generator.set_train_local(config, True)\n",
    "        self.proposal_generator_test = Proposal(config,\n",
    "                                                config.test_batch_size,\n",
    "                                                config.activate_num_classes,\n",
    "                                                config.use_sigmoid_cls)\n",
    "        self.proposal_generator_test.set_train_local(config, False)\n",
    "\n",
    "        # Assign and sampler stage two\n",
    "        self.bbox_assigner_sampler_for_rcnn = BboxAssignSampleForRcnn(config, self.train_batch_size,\n",
    "                                                                      config.num_bboxes_stage2, True)\n",
    "        self.decode = P.BoundingBoxDecode(max_shape=(768, 1280), means=self.target_means, \\\n",
    "                                          stds=self.target_stds)\n",
    "\n",
    "        # Roi\n",
    "        self.init_roi(config)\n",
    "\n",
    "        # Rcnn\n",
    "        self.rcnn_cls = RcnnCls(config, self.train_batch_size, self.num_classes)\n",
    "        self.rcnn_mask = RcnnMask(config, self.train_batch_size, self.num_classes)\n",
    "\n",
    "        # Op declare\n",
    "        self.squeeze = P.Squeeze()\n",
    "        self.cast = P.Cast()\n",
    "\n",
    "        self.concat = P.Concat(axis=0)\n",
    "        self.concat_1 = P.Concat(axis=1)\n",
    "        self.concat_2 = P.Concat(axis=2)\n",
    "        self.reshape = P.Reshape()\n",
    "        self.select = P.Select()\n",
    "        self.greater = P.Greater()\n",
    "        self.transpose = P.Transpose()\n",
    "\n",
    "        # Test mode\n",
    "        self.init_test_mode(config)\n",
    "\n",
    "        # Improve speed\n",
    "        self.concat_start = min(self.num_classes - 2, 55)\n",
    "        self.concat_end = (self.num_classes - 1)\n",
    "\n",
    "        # Init tensor\n",
    "        self.init_tensor(config)\n",
    "\n",
    "    def init_roi(self, config):\n",
    "        self.roi_align = SingleRoIExtractor(config,\n",
    "                                            config.roi_layer,\n",
    "                                            config.roi_align_out_channels,\n",
    "                                            config.roi_align_featmap_strides,\n",
    "                                            self.train_batch_size,\n",
    "                                            config.roi_align_finest_scale,\n",
    "                                            mask=False)\n",
    "        self.roi_align.set_train_local(config, True)\n",
    "\n",
    "        self.roi_align_mask = SingleRoIExtractor(config,\n",
    "                                                 config.roi_layer,\n",
    "                                                 config.roi_align_out_channels,\n",
    "                                                 config.roi_align_featmap_strides,\n",
    "                                                 self.train_batch_size,\n",
    "                                                 config.roi_align_finest_scale,\n",
    "                                                 mask=True)\n",
    "        self.roi_align_mask.set_train_local(config, True)\n",
    "\n",
    "        self.roi_align_test = SingleRoIExtractor(config,\n",
    "                                                 config.roi_layer,\n",
    "                                                 config.roi_align_out_channels,\n",
    "                                                 config.roi_align_featmap_strides,\n",
    "                                                 1,\n",
    "                                                 config.roi_align_finest_scale,\n",
    "                                                 mask=False)\n",
    "        self.roi_align_test.set_train_local(config, False)\n",
    "\n",
    "        self.roi_align_mask_test = SingleRoIExtractor(config,\n",
    "                                                      config.roi_layer,\n",
    "                                                      config.roi_align_out_channels,\n",
    "                                                      config.roi_align_featmap_strides,\n",
    "                                                      1,\n",
    "                                                      config.roi_align_finest_scale,\n",
    "                                                      mask=True)\n",
    "        self.roi_align_mask_test.set_train_local(config, False)\n",
    "\n",
    "    def init_test_mode(self, config):\n",
    "        self.test_batch_size = config.test_batch_size\n",
    "        self.split = P.Split(axis=0, output_num=self.test_batch_size)\n",
    "        self.split_shape = P.Split(axis=0, output_num=4)\n",
    "        self.split_scores = P.Split(axis=1, output_num=self.num_classes)\n",
    "        self.split_fb_mask = P.Split(axis=1, output_num=self.num_classes)\n",
    "        self.split_cls = P.Split(axis=0, output_num=self.num_classes-1)\n",
    "        self.tile = P.Tile()\n",
    "        self.gather = P.GatherNd()\n",
    "\n",
    "        self.rpn_max_num = config.rpn_max_num\n",
    "\n",
    "        self.zeros_for_nms = Tensor(np.zeros((self.rpn_max_num, 3)).astype(self.np_cast_type))\n",
    "        self.ones_mask = np.ones((self.rpn_max_num, 1)).astype(bool)\n",
    "        self.zeros_mask = np.zeros((self.rpn_max_num, 1)).astype(bool)\n",
    "        self.bbox_mask = Tensor(np.concatenate((self.ones_mask, self.zeros_mask,\n",
    "                                                self.ones_mask, self.zeros_mask), axis=1))\n",
    "        self.nms_pad_mask = Tensor(np.concatenate((self.ones_mask, self.ones_mask,\n",
    "                                                   self.ones_mask, self.ones_mask, self.zeros_mask), axis=1))\n",
    "\n",
    "        self.test_score_thresh = Tensor(np.ones((self.rpn_max_num, 1)).astype(self.np_cast_type) * \\\n",
    "                                        config.test_score_thr)\n",
    "        self.test_score_zeros = Tensor(np.ones((self.rpn_max_num, 1)).astype(self.np_cast_type) * 0)\n",
    "        self.test_box_zeros = Tensor(np.ones((self.rpn_max_num, 4)).astype(self.np_cast_type) * -1)\n",
    "        self.test_iou_thr = Tensor(np.ones((self.rpn_max_num, 1)).astype(self.np_cast_type) * config.test_iou_thr)\n",
    "        self.test_max_per_img = config.test_max_per_img\n",
    "        self.nms_test = P.NMSWithMask(config.test_iou_thr)\n",
    "        self.softmax = P.Softmax(axis=1)\n",
    "        self.logicand = P.LogicalAnd()\n",
    "        self.oneslike = P.OnesLike()\n",
    "        self.test_topk = P.TopK(sorted=True)\n",
    "        self.test_num_proposal = self.test_batch_size * self.rpn_max_num\n",
    "\n",
    "    def init_tensor(self, config):\n",
    "        roi_align_index = [np.array(np.ones((config.num_expected_pos_stage2 + \\\n",
    "                                             config.num_expected_neg_stage2, 1)) * i,\n",
    "                                    dtype=self.np_cast_type) for i in range(self.train_batch_size)]\n",
    "\n",
    "        roi_align_index_test = [np.array(np.ones((config.rpn_max_num, 1)) * i, dtype=self.np_cast_type) \\\n",
    "                                for i in range(self.test_batch_size)]\n",
    "\n",
    "        self.roi_align_index_tensor = Tensor(np.concatenate(roi_align_index))\n",
    "        self.roi_align_index_test_tensor = Tensor(np.concatenate(roi_align_index_test))\n",
    "\n",
    "        roi_align_index_pos = [np.array(np.ones((config.num_expected_pos_stage2, 1)) * i,\n",
    "                                        dtype=self.np_cast_type) for i in range(self.train_batch_size)]\n",
    "        self.roi_align_index_tensor_pos = Tensor(np.concatenate(roi_align_index_pos))\n",
    "\n",
    "        self.rcnn_loss_cls_weight = Tensor(np.array(config.rcnn_loss_cls_weight).astype(self.np_cast_type))\n",
    "        self.rcnn_loss_reg_weight = Tensor(np.array(config.rcnn_loss_reg_weight).astype(self.np_cast_type))\n",
    "        self.rcnn_loss_mask_fb_weight = Tensor(np.array(config.rcnn_loss_mask_fb_weight).astype(self.np_cast_type))\n",
    "\n",
    "        self.argmax_with_value = P.ArgMaxWithValue(axis=1)\n",
    "        self.on_value = Tensor(1.0, mstype.float32)\n",
    "        self.off_value = Tensor(0.0, mstype.float32)\n",
    "        self.onehot = P.OneHot()\n",
    "        self.reducesum = P.ReduceSum()\n",
    "        self.sigmoid = P.Sigmoid()\n",
    "        self.expand_dims = P.ExpandDims()\n",
    "        self.test_mask_fb_zeros = Tensor(np.zeros((self.rpn_max_num, 28, 28)).astype(self.np_cast_type))\n",
    "        self.value = Tensor(1.0, self.cast_type)\n",
    "\n",
    "    def construct(self, img_data, img_metas, gt_bboxes, gt_labels, gt_valids, gt_masks):\n",
    "        \"\"\"Construct for Mask R-CNN net.\"\"\"\n",
    "        x = self.backbone(img_data)\n",
    "        x = self.fpn_ncek(x)\n",
    "\n",
    "        rpn_loss, cls_score, bbox_pred, rpn_cls_loss, rpn_reg_loss, _ = self.rpn_with_loss(x,\n",
    "                                                                                           img_metas,\n",
    "                                                                                           self.anchor_list,\n",
    "                                                                                           gt_bboxes,\n",
    "                                                                                           self.gt_labels_stage1,\n",
    "                                                                                           gt_valids)\n",
    "\n",
    "        if self.training:\n",
    "            proposal, proposal_mask = self.proposal_generator(cls_score, bbox_pred, self.anchor_list)\n",
    "        else:\n",
    "            proposal, proposal_mask = self.proposal_generator_test(cls_score, bbox_pred, self.anchor_list)\n",
    "\n",
    "        gt_labels = self.cast(gt_labels, mstype.int32)\n",
    "        gt_valids = self.cast(gt_valids, mstype.int32)\n",
    "        bboxes_tuple = ()\n",
    "        deltas_tuple = ()\n",
    "        labels_tuple = ()\n",
    "        mask_tuple = ()\n",
    "\n",
    "        pos_bboxes_tuple = ()\n",
    "        pos_mask_fb_tuple = ()\n",
    "        pos_labels_tuple = ()\n",
    "        pos_mask_tuple = ()\n",
    "\n",
    "        if self.training:\n",
    "            for i in range(self.train_batch_size):\n",
    "                gt_bboxes_i = self.squeeze(gt_bboxes[i:i + 1:1, ::])\n",
    "\n",
    "                gt_labels_i = self.squeeze(gt_labels[i:i + 1:1, ::])\n",
    "                gt_labels_i = self.cast(gt_labels_i, mstype.uint8)\n",
    "\n",
    "                gt_valids_i = self.squeeze(gt_valids[i:i + 1:1, ::])\n",
    "                gt_valids_i = self.cast(gt_valids_i, mstype.bool_)\n",
    "\n",
    "                gt_masks_i = self.squeeze(gt_masks[i:i + 1:1, ::])\n",
    "                gt_masks_i = self.cast(gt_masks_i, mstype.bool_)\n",
    "\n",
    "                bboxes, deltas, labels, mask, pos_bboxes, pos_mask_fb, pos_labels, pos_mask = \\\n",
    "                    self.bbox_assigner_sampler_for_rcnn(gt_bboxes_i,\n",
    "                                                        gt_labels_i,\n",
    "                                                        proposal_mask[i],\n",
    "                                                        proposal[i][::, 0:4:1],\n",
    "                                                        gt_valids_i,\n",
    "                                                        gt_masks_i)\n",
    "                bboxes_tuple += (bboxes,)\n",
    "                deltas_tuple += (deltas,)\n",
    "                labels_tuple += (labels,)\n",
    "                mask_tuple += (mask,)\n",
    "\n",
    "                pos_bboxes_tuple += (pos_bboxes,)\n",
    "                pos_mask_fb_tuple += (pos_mask_fb,)\n",
    "                pos_labels_tuple += (pos_labels,)\n",
    "                pos_mask_tuple += (pos_mask,)\n",
    "\n",
    "            bbox_targets = self.concat(deltas_tuple)\n",
    "            rcnn_labels = self.concat(labels_tuple)\n",
    "            bbox_targets = F.stop_gradient(bbox_targets)\n",
    "            rcnn_labels = F.stop_gradient(rcnn_labels)\n",
    "            rcnn_labels = self.cast(rcnn_labels, mstype.int32)\n",
    "\n",
    "            rcnn_pos_masks_fb = self.concat(pos_mask_fb_tuple)\n",
    "            rcnn_pos_masks_fb = F.stop_gradient(rcnn_pos_masks_fb)\n",
    "            rcnn_pos_labels = self.concat(pos_labels_tuple)\n",
    "            rcnn_pos_labels = F.stop_gradient(rcnn_pos_labels)\n",
    "            rcnn_pos_labels = self.cast(rcnn_pos_labels, mstype.int32)\n",
    "        else:\n",
    "            mask_tuple += proposal_mask\n",
    "            bbox_targets = proposal_mask\n",
    "            rcnn_labels = proposal_mask\n",
    "\n",
    "            rcnn_pos_masks_fb = proposal_mask\n",
    "            rcnn_pos_labels = proposal_mask\n",
    "            for p_i in proposal:\n",
    "                bboxes_tuple += (p_i[::, 0:4:1],)\n",
    "\n",
    "        bboxes_all, rois, pos_rois = self.rois(bboxes_tuple, pos_bboxes_tuple)\n",
    "\n",
    "        if self.training:\n",
    "            roi_feats = self.roi_align(rois,\n",
    "                                       self.cast(x[0], mstype.float32),\n",
    "                                       self.cast(x[1], mstype.float32),\n",
    "                                       self.cast(x[2], mstype.float32),\n",
    "                                       self.cast(x[3], mstype.float32))\n",
    "        else:\n",
    "            roi_feats = self.roi_align_test(rois,\n",
    "                                            self.cast(x[0], mstype.float32),\n",
    "                                            self.cast(x[1], mstype.float32),\n",
    "                                            self.cast(x[2], mstype.float32),\n",
    "                                            self.cast(x[3], mstype.float32))\n",
    "\n",
    "\n",
    "        roi_feats = self.cast(roi_feats, self.cast_type)\n",
    "        rcnn_masks = self.concat(mask_tuple)\n",
    "        rcnn_masks = F.stop_gradient(rcnn_masks)\n",
    "        rcnn_mask_squeeze = self.squeeze(self.cast(rcnn_masks, mstype.bool_))\n",
    "\n",
    "        rcnn_pos_masks = self.concat(pos_mask_tuple)\n",
    "        rcnn_pos_masks = F.stop_gradient(rcnn_pos_masks)\n",
    "        rcnn_pos_mask_squeeze = self.squeeze(self.cast(rcnn_pos_masks, mstype.bool_))\n",
    "\n",
    "        rcnn_cls_loss, rcnn_reg_loss = self.rcnn_cls(roi_feats,\n",
    "                                                     bbox_targets,\n",
    "                                                     rcnn_labels,\n",
    "                                                     rcnn_mask_squeeze)\n",
    "\n",
    "        if self.training:\n",
    "            return self.get_output_train(pos_rois, x, rcnn_pos_labels, rcnn_pos_mask_squeeze, rcnn_pos_masks_fb,\n",
    "                                         rpn_loss, rpn_cls_loss, rpn_reg_loss, rcnn_cls_loss, rcnn_reg_loss)\n",
    "\n",
    "        return self.get_output_eval(x, bboxes_all, rcnn_cls_loss, rcnn_reg_loss, rcnn_masks, img_metas)\n",
    "\n",
    "    def rois(self, bboxes_tuple, pos_bboxes_tuple):\n",
    "        pos_rois = None\n",
    "        if self.training:\n",
    "            if self.train_batch_size > 1:\n",
    "                bboxes_all = self.concat(bboxes_tuple)\n",
    "                pos_bboxes_all = self.concat(pos_bboxes_tuple)\n",
    "            else:\n",
    "                bboxes_all = bboxes_tuple[0]\n",
    "                pos_bboxes_all = pos_bboxes_tuple[0]\n",
    "            rois = self.concat_1((self.roi_align_index_tensor, bboxes_all))\n",
    "            pos_rois = self.concat_1((self.roi_align_index_tensor_pos, pos_bboxes_all))\n",
    "            pos_rois = self.cast(pos_rois, mstype.float32)\n",
    "            pos_rois = F.stop_gradient(pos_rois)\n",
    "        else:\n",
    "            if self.test_batch_size > 1:\n",
    "                bboxes_all = self.concat(bboxes_tuple)\n",
    "            else:\n",
    "                bboxes_all = bboxes_tuple[0]\n",
    "            rois = self.concat_1((self.roi_align_index_test_tensor, bboxes_all))\n",
    "\n",
    "        rois = self.cast(rois, mstype.float32)\n",
    "        rois = F.stop_gradient(rois)\n",
    "\n",
    "        return bboxes_all, rois, pos_rois\n",
    "\n",
    "    def get_output_train(self, pos_rois, x, rcnn_pos_labels, rcnn_pos_mask_squeeze, rcnn_pos_masks_fb,\n",
    "                         rpn_loss, rpn_cls_loss, rpn_reg_loss, rcnn_cls_loss, rcnn_reg_loss):\n",
    "        output = ()\n",
    "        roi_feats_mask = self.roi_align_mask(pos_rois,\n",
    "                                             self.cast(x[0], mstype.float32),\n",
    "                                             self.cast(x[1], mstype.float32),\n",
    "                                             self.cast(x[2], mstype.float32),\n",
    "                                             self.cast(x[3], mstype.float32))\n",
    "        roi_feats_mask = self.cast(roi_feats_mask, self.cast_type)\n",
    "        rcnn_mask_fb_loss = self.rcnn_mask(roi_feats_mask,\n",
    "                                           rcnn_pos_labels,\n",
    "                                           rcnn_pos_mask_squeeze,\n",
    "                                           rcnn_pos_masks_fb)\n",
    "\n",
    "        rcnn_loss = self.rcnn_loss_cls_weight * rcnn_cls_loss + self.rcnn_loss_reg_weight * rcnn_reg_loss + \\\n",
    "                    self.rcnn_loss_mask_fb_weight * rcnn_mask_fb_loss\n",
    "        output += (rpn_loss, rcnn_loss, rpn_cls_loss, rpn_reg_loss,\n",
    "                   rcnn_cls_loss, rcnn_reg_loss, rcnn_mask_fb_loss)\n",
    "        return output\n",
    "\n",
    "    def get_output_eval(self, x, bboxes_all, rcnn_cls_loss, rcnn_reg_loss, rcnn_masks, img_metas):\n",
    "        mask_fb_pred_all = self.rcnn_mask_test(x, bboxes_all, rcnn_cls_loss, rcnn_reg_loss)\n",
    "        output = self.get_det_bboxes(rcnn_cls_loss, rcnn_reg_loss, rcnn_masks, bboxes_all,\n",
    "                                     img_metas, mask_fb_pred_all)\n",
    "        return output\n",
    "\n",
    "    def get_det_bboxes(self, cls_logits, reg_logits, mask_logits, rois, img_metas, mask_fb_pred_all):\n",
    "        \"\"\"Get the actual detection box.\"\"\"\n",
    "        scores = self.softmax(cls_logits / self.value)\n",
    "        mask_fb_logits = self.sigmoid(mask_fb_pred_all)\n",
    "\n",
    "        boxes_all = ()\n",
    "        for i in range(self.num_classes):\n",
    "            k = i * 4\n",
    "            reg_logits_i = self.squeeze(reg_logits[::, k:k+4:1])\n",
    "            out_boxes_i = self.decode(rois, reg_logits_i)\n",
    "            boxes_all += (out_boxes_i,)\n",
    "\n",
    "        img_metas_all = self.split(img_metas)\n",
    "        scores_all = self.split(scores)\n",
    "        mask_all = self.split(self.cast(mask_logits, mstype.int32))\n",
    "        mask_fb_all = self.split(mask_fb_logits)\n",
    "\n",
    "        boxes_all_with_batchsize = ()\n",
    "        for i in range(self.test_batch_size):\n",
    "            scale = self.split_shape(self.squeeze(img_metas_all[i]))\n",
    "            scale_h = scale[2]\n",
    "            scale_w = scale[3]\n",
    "            boxes_tuple = ()\n",
    "            for j in range(self.num_classes):\n",
    "                boxes_tmp = self.split(boxes_all[j])\n",
    "                out_boxes_h = boxes_tmp[i] / scale_h\n",
    "                out_boxes_w = boxes_tmp[i] / scale_w\n",
    "                boxes_tuple += (self.select(self.bbox_mask, out_boxes_w, out_boxes_h),)\n",
    "            boxes_all_with_batchsize += (boxes_tuple,)\n",
    "\n",
    "        output = self.multiclass_nms(boxes_all_with_batchsize, scores_all, mask_all, mask_fb_all)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def multiclass_nms(self, boxes_all, scores_all, mask_all, mask_fb_all):\n",
    "        \"\"\"Multiscale postprocessing.\"\"\"\n",
    "        all_bboxes = ()\n",
    "        all_labels = ()\n",
    "        all_masks = ()\n",
    "        all_masks_fb = ()\n",
    "\n",
    "        for i in range(self.test_batch_size):\n",
    "            bboxes = boxes_all[i]\n",
    "            scores = scores_all[i]\n",
    "            masks = self.cast(mask_all[i], mstype.bool_)\n",
    "            masks_fb = mask_fb_all[i]\n",
    "            _mask_fb_all = self.split_fb_mask(masks_fb)\n",
    "\n",
    "            res_boxes_tuple = ()\n",
    "            res_labels_tuple = ()\n",
    "            res_masks_tuple = ()\n",
    "            res_masks_fb_tuple = ()\n",
    "\n",
    "            for j in range(self.num_classes - 1):\n",
    "                k = j + 1\n",
    "                _cls_scores = scores[::, k:k + 1:1]\n",
    "                _bboxes = self.squeeze(bboxes[k])\n",
    "                _mask_o = self.reshape(masks, (self.rpn_max_num, 1))\n",
    "                _masks_fb = self.squeeze(_mask_fb_all[k])\n",
    "\n",
    "                cls_mask = self.greater(_cls_scores, self.test_score_thresh)\n",
    "                _mask = self.logicand(_mask_o, cls_mask)\n",
    "\n",
    "                _reg_mask = self.cast(self.tile(self.cast(_mask, mstype.int32), (1, 4)), mstype.bool_)\n",
    "\n",
    "                _bboxes = self.select(_reg_mask, _bboxes, self.test_box_zeros)\n",
    "                _fb_mask = self.expand_dims(_mask, -1)\n",
    "                _mask_fb_mask = self.cast(self.tile(self.cast(_fb_mask, mstype.int32), (1, 28, 28)), mstype.bool_)\n",
    "                _masks_fb = self.select(_mask_fb_mask, _masks_fb, self.test_mask_fb_zeros)\n",
    "                _cls_scores = self.select(_mask, _cls_scores, self.test_score_zeros)\n",
    "                __cls_scores = self.squeeze(_cls_scores)\n",
    "                scores_sorted, topk_inds = self.test_topk(__cls_scores, self.rpn_max_num)\n",
    "                topk_inds = self.reshape(topk_inds, (self.rpn_max_num, 1))\n",
    "                scores_sorted = self.reshape(scores_sorted, (self.rpn_max_num, 1))\n",
    "                _bboxes_sorted = self.gather(_bboxes, topk_inds)\n",
    "                _mask_fb_sorted = self.gather(_masks_fb, topk_inds)\n",
    "                _mask_sorted = self.gather(_mask, topk_inds)\n",
    "\n",
    "                scores_sorted = self.tile(scores_sorted, (1, 4))\n",
    "                cls_dets = self.concat_1((_bboxes_sorted, scores_sorted))\n",
    "                cls_dets = P.Slice()(cls_dets, (0, 0), (self.rpn_max_num, 5))\n",
    "\n",
    "                cls_dets, _index, _mask_nms = self.nms_test(cls_dets)\n",
    "                _index = self.reshape(_index, (self.rpn_max_num, 1))\n",
    "                _mask_nms = self.reshape(_mask_nms, (self.rpn_max_num, 1))\n",
    "\n",
    "                _mask_n = self.gather(_mask_sorted, _index)\n",
    "                _mask_n = self.logicand(_mask_n, _mask_nms)\n",
    "\n",
    "                _mask_fb = self.gather(_mask_fb_sorted, _index)\n",
    "\n",
    "                cls_labels = self.oneslike(_index) * j\n",
    "                res_boxes_tuple += (cls_dets,)\n",
    "                res_labels_tuple += (cls_labels,)\n",
    "                res_masks_tuple += (_mask_n,)\n",
    "                res_masks_fb_tuple += (_mask_fb,)\n",
    "\n",
    "            res_boxes_start = self.concat(res_boxes_tuple[:self.concat_start])\n",
    "            res_labels_start = self.concat(res_labels_tuple[:self.concat_start])\n",
    "            res_masks_start = self.concat(res_masks_tuple[:self.concat_start])\n",
    "            res_masks_fb_start = self.concat(res_masks_fb_tuple[:self.concat_start])\n",
    "\n",
    "            res_boxes_end = self.concat(res_boxes_tuple[self.concat_start:self.concat_end])\n",
    "            res_labels_end = self.concat(res_labels_tuple[self.concat_start:self.concat_end])\n",
    "            res_masks_end = self.concat(res_masks_tuple[self.concat_start:self.concat_end])\n",
    "            res_masks_fb_end = self.concat(res_masks_fb_tuple[self.concat_start:self.concat_end])\n",
    "\n",
    "            res_boxes = self.concat((res_boxes_start, res_boxes_end))\n",
    "            res_labels = self.concat((res_labels_start, res_labels_end))\n",
    "            res_masks = self.concat((res_masks_start, res_masks_end))\n",
    "            res_masks_fb = self.concat((res_masks_fb_start, res_masks_fb_end))\n",
    "\n",
    "            reshape_size = (self.num_classes - 1) * self.rpn_max_num\n",
    "            res_boxes = self.reshape(res_boxes, (1, reshape_size, 5))\n",
    "            res_labels = self.reshape(res_labels, (1, reshape_size, 1))\n",
    "            res_masks = self.reshape(res_masks, (1, reshape_size, 1))\n",
    "            res_masks_fb = self.reshape(res_masks_fb, (1, reshape_size, 28, 28))\n",
    "\n",
    "            all_bboxes += (res_boxes,)\n",
    "            all_labels += (res_labels,)\n",
    "            all_masks += (res_masks,)\n",
    "            all_masks_fb += (res_masks_fb,)\n",
    "\n",
    "        all_bboxes = self.concat(all_bboxes)\n",
    "        all_labels = self.concat(all_labels)\n",
    "        all_masks = self.concat(all_masks)\n",
    "        all_masks_fb = self.concat(all_masks_fb)\n",
    "        return all_bboxes, all_labels, all_masks, all_masks_fb\n",
    "\n",
    "    def get_anchors(self, featmap_sizes):\n",
    "        \"\"\"Get anchors according to feature map sizes.\n",
    "\n",
    "        Args:\n",
    "            featmap_sizes (list[tuple]): Multi-level feature map sizes.\n",
    "            img_metas (list[dict]): Image meta info.\n",
    "\n",
    "        Returns:\n",
    "            tuple: anchors of each image, valid flags of each image\n",
    "        \"\"\"\n",
    "        num_levels = len(featmap_sizes)\n",
    "\n",
    "        # since feature map sizes of all images are the same, we only compute\n",
    "        # anchors for one time\n",
    "        multi_level_anchors = ()\n",
    "        for i in range(num_levels):\n",
    "            anchors = self.anchor_generators[i].grid_anchors(\n",
    "                featmap_sizes[i], self.anchor_strides[i])\n",
    "            multi_level_anchors += (Tensor(anchors.astype(self.np_cast_type)),)\n",
    "\n",
    "        return multi_level_anchors\n",
    "\n",
    "    def rcnn_mask_test(self, x, rois, cls_pred, reg_pred):\n",
    "        \"\"\"Prediction masks in an images by the bounding boxes\n",
    "        \"\"\"\n",
    "        cls_scores = self.softmax(cls_pred / self.value)\n",
    "\n",
    "        cls_scores_all = self.split(cls_scores)\n",
    "        reg_pred = self.reshape(reg_pred, (-1, self.num_classes, 4))\n",
    "        reg_pred_all = self.split(reg_pred)\n",
    "        rois_all = self.split(rois)\n",
    "        boxes_tuple = ()\n",
    "        for i in range(self.test_batch_size):\n",
    "            cls_score_max_index, _ = self.argmax_with_value(cls_scores_all[i])\n",
    "            cls_score_max_index = self.cast(self.onehot(cls_score_max_index, self.num_classes,\n",
    "                                                        self.on_value, self.off_value), self.cast_type)\n",
    "            cls_score_max_index = self.expand_dims(cls_score_max_index, -1)\n",
    "            cls_score_max_index = self.tile(cls_score_max_index, (1, 1, 4))\n",
    "            reg_pred_max = reg_pred_all[i] * cls_score_max_index\n",
    "            reg_pred_max = self.reducesum(reg_pred_max, 1)\n",
    "            out_boxes_i = self.decode(rois_all[i], reg_pred_max)\n",
    "            boxes_tuple += (out_boxes_i,)\n",
    "\n",
    "        boxes_all = self.concat(boxes_tuple)\n",
    "        boxes_rois = self.concat_1((self.roi_align_index_test_tensor, boxes_all))\n",
    "        boxes_rois = self.cast(boxes_rois, self.cast_type)\n",
    "        roi_feats_mask_test = self.roi_align_mask_test(boxes_rois,\n",
    "                                                       self.cast(x[0], mstype.float32),\n",
    "                                                       self.cast(x[1], mstype.float32),\n",
    "                                                       self.cast(x[2], mstype.float32),\n",
    "                                                       self.cast(x[3], mstype.float32))\n",
    "        roi_feats_mask_test = self.cast(roi_feats_mask_test, self.cast_type)\n",
    "        mask_fb_pred_all = self.rcnn_mask(roi_feats_mask_test)\n",
    "        return mask_fb_pred_all\n",
    "\n",
    "\n",
    "def bbox_overlaps(bboxes1, bboxes2, mode='iou'):\n",
    "    \"\"\"Calculate the ious between each bbox of bboxes1 and bboxes2.\n",
    "\n",
    "    Args:\n",
    "        bboxes1(ndarray): shape (n, 4)\n",
    "        bboxes2(ndarray): shape (k, 4)\n",
    "        mode(str): iou (intersection over union) or iof (intersection\n",
    "            over foreground)\n",
    "\n",
    "    Returns:\n",
    "        ious(ndarray): shape (n, k)\n",
    "    \"\"\"\n",
    "\n",
    "    assert mode in ['iou', 'iof']\n",
    "\n",
    "    bboxes1 = bboxes1.astype(np.float32)\n",
    "    bboxes2 = bboxes2.astype(np.float32)\n",
    "    rows = bboxes1.shape[0]\n",
    "    cols = bboxes2.shape[0]\n",
    "    ious = np.zeros((rows, cols), dtype=np.float32)\n",
    "    if rows * cols == 0:\n",
    "        return ious\n",
    "    exchange = False\n",
    "    if bboxes1.shape[0] > bboxes2.shape[0]:\n",
    "        bboxes1, bboxes2 = bboxes2, bboxes1\n",
    "        ious = np.zeros((cols, rows), dtype=np.float32)\n",
    "        exchange = True\n",
    "    area1 = (bboxes1[:, 2] - bboxes1[:, 0] + 1) * (bboxes1[:, 3] - bboxes1[:, 1] + 1)\n",
    "    area2 = (bboxes2[:, 2] - bboxes2[:, 0] + 1) * (bboxes2[:, 3] - bboxes2[:, 1] + 1)\n",
    "    for i in range(bboxes1.shape[0]):\n",
    "        x_start = np.maximum(bboxes1[i, 0], bboxes2[:, 0])\n",
    "        y_start = np.maximum(bboxes1[i, 1], bboxes2[:, 1])\n",
    "        x_end = np.minimum(bboxes1[i, 2], bboxes2[:, 2])\n",
    "        y_end = np.minimum(bboxes1[i, 3], bboxes2[:, 3])\n",
    "        overlap = np.maximum(x_end - x_start + 1, 0) * np.maximum(\n",
    "            y_end - y_start + 1, 0)\n",
    "        if mode == 'iou':\n",
    "            union = area1[i] + area2 - overlap\n",
    "        else:\n",
    "            union = area1[i] if not exchange else area2\n",
    "        ious[i, :] = overlap / union\n",
    "    if exchange:\n",
    "        ious = ious.T\n",
    "    return ious\n",
    "\n",
    "\n",
    "class PhotoMetricDistortion:\n",
    "    \"\"\"Photo Metric Distortion\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 brightness_delta=32,\n",
    "                 contrast_range=(0.5, 1.5),\n",
    "                 saturation_range=(0.5, 1.5),\n",
    "                 hue_delta=18):\n",
    "        self.brightness_delta = brightness_delta\n",
    "        self.contrast_lower, self.contrast_upper = contrast_range\n",
    "        self.saturation_lower, self.saturation_upper = saturation_range\n",
    "        self.hue_delta = hue_delta\n",
    "\n",
    "    def __call__(self, img, boxes, labels):\n",
    "        # random brightness\n",
    "        img = img.astype('float32')\n",
    "\n",
    "        if random.randint(2):\n",
    "            delta = random.uniform(-self.brightness_delta,\n",
    "                                   self.brightness_delta)\n",
    "            img += delta\n",
    "\n",
    "        # mode == 0 --> do random contrast first\n",
    "        # mode == 1 --> do random contrast last\n",
    "        mode = random.randint(2)\n",
    "        if mode == 1:\n",
    "            if random.randint(2):\n",
    "                alpha = random.uniform(self.contrast_lower,\n",
    "                                       self.contrast_upper)\n",
    "                img *= alpha\n",
    "\n",
    "        # convert color from BGR to HSV\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # random saturation\n",
    "        if random.randint(2):\n",
    "            img[..., 1] *= random.uniform(self.saturation_lower,\n",
    "                                          self.saturation_upper)\n",
    "\n",
    "        # random hue\n",
    "        if random.randint(2):\n",
    "            img[..., 0] += random.uniform(-self.hue_delta, self.hue_delta)\n",
    "            img[..., 0][img[..., 0] > 360] -= 360\n",
    "            img[..., 0][img[..., 0] < 0] += 360\n",
    "\n",
    "        # convert color from HSV to BGR\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "        # random contrast\n",
    "        if mode == 0:\n",
    "            if random.randint(2):\n",
    "                alpha = random.uniform(self.contrast_lower,\n",
    "                                       self.contrast_upper)\n",
    "                img *= alpha\n",
    "\n",
    "        # randomly swap channels\n",
    "        if random.randint(2):\n",
    "            img = img[..., random.permutation(3)]\n",
    "\n",
    "        return img, boxes, labels\n",
    "\n",
    "\n",
    "class Expand:\n",
    "    \"\"\"expand image\"\"\"\n",
    "\n",
    "    def __init__(self, mean=(0, 0, 0), to_rgb=True, ratio_range=(1, 4)):\n",
    "        if to_rgb:\n",
    "            self.mean = mean[::-1]\n",
    "        else:\n",
    "            self.mean = mean\n",
    "        self.min_ratio, self.max_ratio = ratio_range\n",
    "\n",
    "    def __call__(self, img, boxes, labels, mask):\n",
    "        if random.randint(2):\n",
    "            return img, boxes, labels, mask\n",
    "\n",
    "        h, w, c = img.shape\n",
    "        ratio = random.uniform(self.min_ratio, self.max_ratio)\n",
    "        expand_img = np.full((int(h * ratio), int(w * ratio), c),\n",
    "                             self.mean).astype(img.dtype)\n",
    "        left = int(random.uniform(0, w * ratio - w))\n",
    "        top = int(random.uniform(0, h * ratio - h))\n",
    "        expand_img[top:top + h, left:left + w] = img\n",
    "        img = expand_img\n",
    "        boxes += np.tile((left, top), 2)\n",
    "\n",
    "        mask_count, mask_h, mask_w = mask.shape\n",
    "        expand_mask = np.zeros((mask_count, int(mask_h * ratio), int(mask_w * ratio))).astype(mask.dtype)\n",
    "        expand_mask[:, top:top + h, left:left + w] = mask\n",
    "        mask = expand_mask\n",
    "\n",
    "        return img, boxes, labels, mask\n",
    "\n",
    "\n",
    "class LossCallBack(Callback):\n",
    "    \"\"\"\n",
    "    Monitor the loss in training.\n",
    "\n",
    "    If the loss is NAN or INF terminating training.\n",
    "\n",
    "    Note:\n",
    "        If per_print_times is 0 do not print loss.\n",
    "\n",
    "    Args:\n",
    "        per_print_times (int): Print loss every times. Default: 1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, per_print_times=1, rank_id=0):\n",
    "        super(LossCallBack, self).__init__()\n",
    "        if not isinstance(per_print_times, int) or per_print_times < 0:\n",
    "            raise ValueError(\"print_step must be int and >= 0.\")\n",
    "        self._per_print_times = per_print_times\n",
    "        self.count = 0\n",
    "        self.loss_sum = 0\n",
    "        self.rank_id = rank_id\n",
    "\n",
    "        global time_stamp_init, time_stamp_first\n",
    "        if not time_stamp_init:\n",
    "            time_stamp_first = time.time()\n",
    "            time_stamp_init = True\n",
    "\n",
    "    def step_end(self, run_context):\n",
    "        cb_params = run_context.original_args()\n",
    "        loss = cb_params.net_outputs.asnumpy()\n",
    "        cur_step_in_epoch = (cb_params.cur_step_num - 1) % cb_params.batch_num + 1\n",
    "\n",
    "        self.count += 1\n",
    "        self.loss_sum += float(loss)\n",
    "\n",
    "        if self.count >= 1:\n",
    "            global time_stamp_first\n",
    "            time_stamp_current = time.time()\n",
    "            total_loss = self.loss_sum / self.count\n",
    "\n",
    "            loss_file = open(\"./loss_{}.log\".format(self.rank_id), \"a+\")\n",
    "            loss_file.write(\"%lu epoch: %s step: %s total_loss: %.5f\" %\n",
    "                            (time_stamp_current - time_stamp_first, cb_params.cur_epoch_num, cur_step_in_epoch,\n",
    "                             total_loss))\n",
    "            loss_file.write(\"\\n\")\n",
    "            loss_file.close()\n",
    "\n",
    "            self.count = 0\n",
    "            self.loss_sum = 0\n",
    "\n",
    "\n",
    "class LossNet(nn.Cell):\n",
    "    \"\"\"MaskRcnn loss method\"\"\"\n",
    "\n",
    "    def construct(self, x1, x2, x3, x4, x5, x6, x7):\n",
    "        return x1 + x2 + x3 + x4 + x5 + x6 + x7\n",
    "\n",
    "\n",
    "class WithLossCell(nn.Cell):\n",
    "    \"\"\"\n",
    "    Wrap the network with loss function to compute loss.\n",
    "\n",
    "    Args:\n",
    "        backbone (Cell): The target network to wrap.\n",
    "        loss_fn (Cell): The loss function used to compute loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, backbone, loss_fn):\n",
    "        super(WithLossCell, self).__init__(auto_prefix=False)\n",
    "        self._backbone = backbone\n",
    "        self._loss_fn = loss_fn\n",
    "\n",
    "    def construct(self, x, img_shape, gt_bboxe, gt_label, gt_num, gt_mask):\n",
    "        loss1, loss2, loss3, loss4, loss5, loss6, loss7 = self._backbone(x, img_shape, gt_bboxe, gt_label,\n",
    "                                                                         gt_num, gt_mask)\n",
    "        return self._loss_fn(loss1, loss2, loss3, loss4, loss5, loss6, loss7)\n",
    "\n",
    "    @property\n",
    "    def backbone_network(self):\n",
    "        \"\"\"\n",
    "        Get the backbone network.\n",
    "\n",
    "        Returns:\n",
    "            Cell, return backbone network.\n",
    "        \"\"\"\n",
    "        return self._backbone\n",
    "\n",
    "\n",
    "class TrainOneStepCell(nn.Cell):\n",
    "    \"\"\"\n",
    "    Network training package class.\n",
    "\n",
    "    Append an optimizer to the training network after that the construct function\n",
    "    can be called to create the backward graph.\n",
    "\n",
    "    Args:\n",
    "        network (Cell): The training network.\n",
    "        optimizer (Cell): Optimizer for updating the weights.\n",
    "        sens (Number): The adjust parameter. Default value is 1.0.\n",
    "        reduce_flag (bool): The reduce flag. Default value is False.\n",
    "        mean (bool): Allreduce method. Default value is False.\n",
    "        degree (int): Device number. Default value is None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, network, optimizer, sens=1.0, reduce_flag=False, mean=True, degree=None):\n",
    "        super(TrainOneStepCell, self).__init__(auto_prefix=False)\n",
    "        self.network = network\n",
    "        self.network.set_grad()\n",
    "        self.weights = ParameterTuple(network.trainable_params())\n",
    "        self.optimizer = optimizer\n",
    "        self.grad = C.GradOperation(get_by_list=True,\n",
    "                                    sens_param=True)\n",
    "\n",
    "        self.sens = Tensor((np.ones((1,)) * sens).astype(np.float32))\n",
    "\n",
    "        self.reduce_flag = reduce_flag\n",
    "        self.hyper_map = C.HyperMap()\n",
    "\n",
    "    def construct(self, x, img_shape, gt_bboxe, gt_label, gt_num, gt_mask):\n",
    "        weights = self.weights\n",
    "        loss = self.network(x, img_shape, gt_bboxe, gt_label, gt_num, gt_mask)\n",
    "        grads = self.grad(self.network, weights)(x, img_shape, gt_bboxe, gt_label, gt_num, gt_mask, self.sens)\n",
    "        if self.reduce_flag:\n",
    "            grads = self.grad_reducer(grads)\n",
    "\n",
    "        return F.depend(loss, self.optimizer(grads))\n",
    "\n",
    "\n",
    "def rescale_with_tuple(img, scale):\n",
    "    h, w = img.shape[:2]\n",
    "    scale_factor = min(max(scale) / max(h, w), min(scale) / min(h, w))\n",
    "    new_size = int(w * float(scale_factor) + 0.5), int(h * float(scale_factor) + 0.5)\n",
    "    rescaled_img = cv2.resize(img, new_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    return rescaled_img, scale_factor\n",
    "\n",
    "\n",
    "def rescale_with_factor(img, scale_factor):\n",
    "    h, w = img.shape[:2]\n",
    "    new_size = int(w * float(scale_factor) + 0.5), int(h * float(scale_factor) + 0.5)\n",
    "    return cv2.resize(img, new_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "\n",
    "def rescale_column(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"rescale operation for image\"\"\"\n",
    "    img_data, scale_factor = rescale_with_tuple(img, (config.img_width, config.img_height))\n",
    "    if img_data.shape[0] > config.img_height:\n",
    "        img_data, scale_factor2 = rescale_with_tuple(img_data, (config.img_height, config.img_height))\n",
    "        scale_factor = scale_factor*scale_factor2\n",
    "\n",
    "    gt_bboxes = gt_bboxes * scale_factor\n",
    "    gt_bboxes[:, 0::2] = np.clip(gt_bboxes[:, 0::2], 0, img_data.shape[1] - 1)\n",
    "    gt_bboxes[:, 1::2] = np.clip(gt_bboxes[:, 1::2], 0, img_data.shape[0] - 1)\n",
    "\n",
    "    gt_mask_data = np.array([\n",
    "        rescale_with_factor(mask, scale_factor)\n",
    "        for mask in gt_mask\n",
    "    ])\n",
    "\n",
    "    pad_h = config.img_height - img_data.shape[0]\n",
    "    pad_w = config.img_width - img_data.shape[1]\n",
    "    assert ((pad_h >= 0) and (pad_w >= 0))\n",
    "\n",
    "    pad_img_data = np.zeros((config.img_height, config.img_width, 3)).astype(img_data.dtype)\n",
    "    pad_img_data[0:img_data.shape[0], 0:img_data.shape[1], :] = img_data\n",
    "\n",
    "    mask_count, mask_h, mask_w = gt_mask_data.shape\n",
    "    pad_mask = np.zeros((mask_count, config.img_height, config.img_width)).astype(gt_mask_data.dtype)\n",
    "    pad_mask[:, 0:mask_h, 0:mask_w] = gt_mask_data\n",
    "\n",
    "    img_shape = (config.img_height, config.img_width, 1.0)\n",
    "    img_shape = np.asarray(img_shape, dtype=np.float32)\n",
    "\n",
    "    return  (pad_img_data, img_shape, gt_bboxes, gt_label, gt_num, pad_mask)\n",
    "\n",
    "\n",
    "def rescale_column_test(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"rescale operation for image of eval\"\"\"\n",
    "    img_data, scale_factor = rescale_with_tuple(img, (config.img_width, config.img_height))\n",
    "    if img_data.shape[0] > config.img_height:\n",
    "        img_data, scale_factor2 = rescale_with_tuple(img_data, (config.img_height, config.img_height))\n",
    "        scale_factor = scale_factor*scale_factor2\n",
    "\n",
    "    pad_h = config.img_height - img_data.shape[0]\n",
    "    pad_w = config.img_width - img_data.shape[1]\n",
    "    assert ((pad_h >= 0) and (pad_w >= 0))\n",
    "\n",
    "    pad_img_data = np.zeros((config.img_height, config.img_width, 3)).astype(img_data.dtype)\n",
    "    pad_img_data[0:img_data.shape[0], 0:img_data.shape[1], :] = img_data\n",
    "\n",
    "    img_shape = np.append(img_shape, (scale_factor, scale_factor))\n",
    "    img_shape = np.asarray(img_shape, dtype=np.float32)\n",
    "\n",
    "    return  (pad_img_data, img_shape, gt_bboxes, gt_label, gt_num, gt_mask)\n",
    "\n",
    "\n",
    "def resize_column(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"resize operation for image\"\"\"\n",
    "    img_data = img\n",
    "    h, w = img_data.shape[:2]\n",
    "    img_data = cv2.resize(img_data, (config.img_width, config.img_height), interpolation=cv2.INTER_LINEAR)\n",
    "    h_scale = config.img_height / h\n",
    "    w_scale = config.img_width / w\n",
    "\n",
    "    scale_factor = np.array(\n",
    "        [w_scale, h_scale, w_scale, h_scale], dtype=np.float32)\n",
    "    img_shape = (config.img_height, config.img_width, 1.0)\n",
    "    img_shape = np.asarray(img_shape, dtype=np.float32)\n",
    "\n",
    "    gt_bboxes = gt_bboxes * scale_factor\n",
    "    gt_bboxes[:, 0::2] = np.clip(gt_bboxes[:, 0::2], 0, img_shape[1] - 1) # x1, x2   [0, W-1]\n",
    "    gt_bboxes[:, 1::2] = np.clip(gt_bboxes[:, 1::2], 0, img_shape[0] - 1) # y1, y2   [0, H-1]\n",
    "\n",
    "    gt_mask_data = np.array([\n",
    "        cv2.resize(mask, (config.img_width, config.img_height), interpolation=cv2.INTER_NEAREST)\n",
    "        for mask in gt_mask\n",
    "    ])\n",
    "    return  (img_data, img_shape, gt_bboxes, gt_label, gt_num, gt_mask_data)\n",
    "\n",
    "\n",
    "def resize_column_test(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"resize operation for image of eval\"\"\"\n",
    "    img_data = img\n",
    "    h, w = img_data.shape[:2]\n",
    "    img_data = cv2.resize(img_data, (config.img_width, config.img_height), interpolation=cv2.INTER_LINEAR)\n",
    "    h_scale = config.img_height / h\n",
    "    w_scale = config.img_width / w\n",
    "\n",
    "    img_shape = np.append(img_shape, (h_scale, w_scale))\n",
    "    img_shape = np.asarray(img_shape, dtype=np.float32)\n",
    "\n",
    "    return  (img_data, img_shape, gt_bboxes, gt_label, gt_num, gt_mask)\n",
    "\n",
    "\n",
    "def impad_to_multiple_column(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"impad operation for image\"\"\"\n",
    "    img_data = cv2.copyMakeBorder(img,\n",
    "                                  0, config.img_height - img.shape[0], 0, config.img_width - img.shape[1],\n",
    "                                  cv2.BORDER_CONSTANT,\n",
    "                                  value=0)\n",
    "    img_data = img_data.astype(np.float32)\n",
    "    return (img_data, img_shape, gt_bboxes, gt_label, gt_num, gt_mask)\n",
    "\n",
    "\n",
    "def imnormalize_column(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"imnormalize operation for image\"\"\"\n",
    "    # Computed from random subset of ImageNet training images\n",
    "    mean = np.asarray([123.675, 116.28, 103.53])\n",
    "    std = np.asarray([58.395, 57.12, 57.375])\n",
    "    img_data = img.copy().astype(np.float32)\n",
    "    cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB, img_data)  # inplace\n",
    "    cv2.subtract(img_data, np.float64(mean.reshape(1, -1)), img_data)  # inplace\n",
    "    cv2.multiply(img_data, 1 / np.float64(std.reshape(1, -1)), img_data)  # inplace\n",
    "\n",
    "    img_data = img_data.astype(np.float32)\n",
    "    return (img_data, img_shape, gt_bboxes, gt_label, gt_num, gt_mask)\n",
    "\n",
    "\n",
    "def flip_column(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"flip operation for image\"\"\"\n",
    "    img_data = img\n",
    "    img_data = np.flip(img_data, axis=1)\n",
    "    flipped = gt_bboxes.copy()\n",
    "    _, w, _ = img_data.shape\n",
    "\n",
    "    flipped[..., 0::4] = w - gt_bboxes[..., 2::4] - 1  # x1 = W-x2-1\n",
    "    flipped[..., 2::4] = w - gt_bboxes[..., 0::4] - 1  # x2 = W-x1-1\n",
    "\n",
    "    gt_mask_data = np.array([mask[:, ::-1] for mask in gt_mask])\n",
    "\n",
    "    return  (img_data, img_shape, flipped, gt_label, gt_num, gt_mask_data)\n",
    "\n",
    "\n",
    "def transpose_column(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"transpose operation for image\"\"\"\n",
    "    if context.get_context(\"device_target\") == \"CPU\" or context.get_context(\"device_target\") == \"GPU\":\n",
    "        platform_dtype = np.float32\n",
    "    else:\n",
    "        platform_dtype = np.float32\n",
    "\n",
    "    img_data = img.transpose(2, 0, 1).copy()\n",
    "    img_data = img_data.astype(platform_dtype)\n",
    "    img_shape = img_shape.astype(platform_dtype)\n",
    "    gt_bboxes = gt_bboxes.astype(platform_dtype)\n",
    "    gt_label = gt_label.astype(np.int32)\n",
    "    gt_num = gt_num.astype(bool)\n",
    "    gt_mask_data = gt_mask.astype(bool)\n",
    "\n",
    "    return (img_data, img_shape, gt_bboxes, gt_label, gt_num, gt_mask_data)\n",
    "\n",
    "\n",
    "def photo_crop_column(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"photo crop operation for image\"\"\"\n",
    "    random_photo = PhotoMetricDistortion()\n",
    "    img_data, gt_bboxes, gt_label = random_photo(img, gt_bboxes, gt_label)\n",
    "\n",
    "    return (img_data, img_shape, gt_bboxes, gt_label, gt_num, gt_mask)\n",
    "\n",
    "\n",
    "def expand_column(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask):\n",
    "    \"\"\"expand operation for image\"\"\"\n",
    "    expand = Expand()\n",
    "    img, gt_bboxes, gt_label, gt_mask = expand(img, gt_bboxes, gt_label, gt_mask)\n",
    "\n",
    "    return (img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask)\n",
    "\n",
    "\n",
    "def pad_to_max(img, img_shape, gt_bboxes, gt_label, gt_num, gt_mask, instance_count):\n",
    "    pad_max_number = config.max_instance_count\n",
    "    gt_box_new = np.pad(gt_bboxes, ((0, pad_max_number - instance_count), (0, 0)), mode=\"constant\", constant_values=0)\n",
    "    gt_label_new = np.pad(gt_label, ((0, pad_max_number - instance_count)), mode=\"constant\", constant_values=-1)\n",
    "    gt_iscrowd_new = np.pad(gt_num, ((0, pad_max_number - instance_count)), mode=\"constant\", constant_values=1)\n",
    "    gt_iscrowd_new_revert = ~(gt_iscrowd_new.astype(bool))\n",
    "\n",
    "    return img, img_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert, gt_mask\n",
    "\n",
    "\n",
    "def preprocess_fn(image, box, mask, mask_shape, is_training):\n",
    "    \"\"\"Preprocess function for dataset.\"\"\"\n",
    "    def _infer_data(image_bgr, image_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert,\n",
    "                    gt_mask_new, instance_count):\n",
    "        image_shape = image_shape[:2]\n",
    "        input_data = image_bgr, image_shape, gt_box_new, gt_label_new, gt_iscrowd_new_revert, gt_mask_new\n",
    "\n",
    "        if config.keep_ratio:\n",
    "            input_data = rescale_column_test(*input_data)\n",
    "        else:\n",
    "            input_data = resize_column_test(*input_data)\n",
    "        input_data = imnormalize_column(*input_data)\n",
    "\n",
    "        input_data = pad_to_max(*input_data, instance_count)\n",
    "        output_data = transpose_column(*input_data)\n",
    "        return output_data\n",
    "\n",
    "    def _data_aug(image, box, mask, mask_shape, is_training):\n",
    "        \"\"\"Data augmentation function.\"\"\"\n",
    "        image_bgr = image.copy()\n",
    "        image_bgr[:, :, 0] = image[:, :, 2]\n",
    "        image_bgr[:, :, 1] = image[:, :, 1]\n",
    "        image_bgr[:, :, 2] = image[:, :, 0]\n",
    "        image_shape = image_bgr.shape[:2]\n",
    "        instance_count = box.shape[0]\n",
    "        gt_box = box[:, :4]\n",
    "        gt_label = box[:, 4]\n",
    "        gt_iscrowd = box[:, 5]\n",
    "        gt_mask = mask.copy()\n",
    "        n, h, w = mask_shape\n",
    "        gt_mask = gt_mask.reshape(n, h, w)\n",
    "        assert n == box.shape[0]\n",
    "\n",
    "        if not is_training:\n",
    "            return _infer_data(image_bgr, image_shape, gt_box, gt_label, gt_iscrowd, gt_mask, instance_count)\n",
    "\n",
    "        flip = (np.random.rand() < config.flip_ratio)\n",
    "        expand = (np.random.rand() < config.expand_ratio)\n",
    "\n",
    "        input_data = image_bgr, image_shape, gt_box, gt_label, gt_iscrowd, gt_mask\n",
    "\n",
    "        if expand:\n",
    "            input_data = expand_column(*input_data)\n",
    "        if config.keep_ratio:\n",
    "            input_data = rescale_column(*input_data)\n",
    "        else:\n",
    "            input_data = resize_column(*input_data)\n",
    "\n",
    "        input_data = imnormalize_column(*input_data)\n",
    "        if flip:\n",
    "            input_data = flip_column(*input_data)\n",
    "\n",
    "        input_data = pad_to_max(*input_data, instance_count)\n",
    "        output_data = transpose_column(*input_data)\n",
    "        return output_data\n",
    "\n",
    "    return _data_aug(image, box, mask, mask_shape, is_training)\n",
    "\n",
    "\n",
    "def annToMask(ann, height, width):\n",
    "    \"\"\"Convert annotation to RLE and then to binary mask.\"\"\"\n",
    "    from pycocotools import mask as maskHelper\n",
    "    segm = ann['segmentation']\n",
    "    if isinstance(segm, list):\n",
    "        rles = maskHelper.frPyObjects(segm, height, width)\n",
    "        rle = maskHelper.merge(rles)\n",
    "    elif isinstance(segm['counts'], list):\n",
    "        rle = maskHelper.frPyObjects(segm, height, width)\n",
    "    else:\n",
    "        rle = ann['segmentation']\n",
    "    m = maskHelper.decode(rle)\n",
    "    return m\n",
    "\n",
    "\n",
    "def create_coco_label(is_training):\n",
    "    \"\"\"Get image path and annotation from COCO.\"\"\"\n",
    "    from pycocotools.coco import COCO\n",
    "\n",
    "    coco_root = config.coco_root\n",
    "    data_type = config.val_data_type\n",
    "    if is_training:\n",
    "        data_type = config.train_data_type\n",
    "\n",
    "    # Classes need to train or test.\n",
    "    train_cls = config.coco_classes\n",
    "\n",
    "    train_cls_dict = {}\n",
    "    for i, cls in enumerate(train_cls):\n",
    "        train_cls_dict[cls] = i\n",
    "\n",
    "    anno_json = os.path.join(coco_root, config.instance_set.format(data_type))\n",
    "\n",
    "    coco = COCO(anno_json)\n",
    "    classs_dict = {}\n",
    "    cat_ids = coco.loadCats(coco.getCatIds())\n",
    "    for cat in cat_ids:\n",
    "        classs_dict[cat[\"id\"]] = cat[\"name\"]\n",
    "\n",
    "    image_ids = coco.getImgIds()\n",
    "    image_files = []\n",
    "    image_anno_dict = {}\n",
    "    masks = {}\n",
    "    masks_shape = {}\n",
    "    images_num = len(image_ids)\n",
    "    for ind, img_id in enumerate(image_ids):\n",
    "        image_info = coco.loadImgs(img_id)\n",
    "        file_name = image_info[0][\"file_name\"]\n",
    "        image_path = os.path.join(coco_root, data_type, file_name)\n",
    "        if not os.path.isfile(image_path):\n",
    "            print(\"{}/{}: {} is in annotations but not exist\".format(ind + 1, images_num, image_path))\n",
    "            continue\n",
    "        anno_ids = coco.getAnnIds(imgIds=img_id, iscrowd=None)\n",
    "        anno = coco.loadAnns(anno_ids)\n",
    "        image_path = os.path.join(coco_root, data_type, file_name)\n",
    "        annos = []\n",
    "        instance_masks = []\n",
    "        image_height = coco.imgs[img_id][\"height\"]\n",
    "        image_width = coco.imgs[img_id][\"width\"]\n",
    "        if (ind + 1) % 10 == 0:\n",
    "            print(\"{}/{}: parsing annotation for image={}\".format(ind + 1, images_num, file_name))\n",
    "        if not is_training:\n",
    "            image_files.append(image_path)\n",
    "            image_anno_dict[image_path] = np.array([0, 0, 0, 0, 0, 1])\n",
    "            masks[image_path] = np.zeros([1, 1, 1], dtype=bool).tobytes()\n",
    "            masks_shape[image_path] = np.array([1, 1, 1], dtype=np.int32)\n",
    "        else:\n",
    "            for label in anno:\n",
    "                bbox = label[\"bbox\"]\n",
    "                class_name = classs_dict[label[\"category_id\"]]\n",
    "                if class_name in train_cls:\n",
    "                    # get coco mask\n",
    "                    m = annToMask(label, image_height, image_width)\n",
    "                    if m.max() < 1:\n",
    "                        print(\"all black mask!!!!\")\n",
    "                        continue\n",
    "                    # Resize mask for the crowd\n",
    "                    if label['iscrowd'] and (m.shape[0] != image_height or m.shape[1] != image_width):\n",
    "                        m = np.ones([image_height, image_width], dtype=bool)\n",
    "                    instance_masks.append(m)\n",
    "\n",
    "                    # get coco bbox\n",
    "                    x1, x2 = bbox[0], bbox[0] + bbox[2]\n",
    "                    y1, y2 = bbox[1], bbox[1] + bbox[3]\n",
    "                    annos.append([x1, y1, x2, y2] + [train_cls_dict[class_name]] + [int(label[\"iscrowd\"])])\n",
    "                else:\n",
    "                    print(\"not in classes: \", class_name)\n",
    "\n",
    "            image_files.append(image_path)\n",
    "            if annos:\n",
    "                image_anno_dict[image_path] = np.array(annos)\n",
    "                instance_masks = np.stack(instance_masks, axis=0).astype(bool)\n",
    "                masks[image_path] = np.array(instance_masks).tobytes()\n",
    "                masks_shape[image_path] = np.array(instance_masks.shape, dtype=np.int32)\n",
    "            else:\n",
    "                print(\"no annotations for image \", file_name)\n",
    "                image_anno_dict[image_path] = np.array([0, 0, 0, 0, 0, 1])\n",
    "                masks[image_path] = np.zeros([1, image_height, image_width], dtype=bool).tobytes()\n",
    "                masks_shape[image_path] = np.array([1, image_height, image_width], dtype=np.int32)\n",
    "\n",
    "    return image_files, image_anno_dict, masks, masks_shape\n",
    "\n",
    "\n",
    "def data_to_mindrecord_byte_image(dataset=\"coco\", is_training=True, prefix=\"maskrcnn.mindrecord\", file_num=8):\n",
    "    \"\"\"Create MindRecord file.\"\"\"\n",
    "    mindrecord_dir = config.mindrecord_dir\n",
    "    mindrecord_path = os.path.join(mindrecord_dir, prefix)\n",
    "\n",
    "    writer = FileWriter(mindrecord_path, file_num)\n",
    "    if dataset == \"coco\":\n",
    "        image_files, image_anno_dict, masks, masks_shape = create_coco_label(is_training)\n",
    "    else:\n",
    "        print(\"Error unsupported other dataset\")\n",
    "        return\n",
    "\n",
    "    maskrcnn_json = {\n",
    "        \"image\": {\"type\": \"bytes\"},\n",
    "        \"annotation\": {\"type\": \"int32\", \"shape\": [-1, 6]},\n",
    "        \"mask\": {\"type\": \"bytes\"},\n",
    "        \"mask_shape\": {\"type\": \"int32\", \"shape\": [-1]},\n",
    "    }\n",
    "    writer.add_schema(maskrcnn_json, \"maskrcnn_json\")\n",
    "\n",
    "    image_files_num = len(image_files)\n",
    "    for ind, image_name in enumerate(image_files):\n",
    "        with open(image_name, 'rb') as f:\n",
    "            img = f.read()\n",
    "        annos = np.array(image_anno_dict[image_name], dtype=np.int32)\n",
    "        mask = masks[image_name]\n",
    "        mask_shape = masks_shape[image_name]\n",
    "        row = {\"image\": img, \"annotation\": annos, \"mask\": mask, \"mask_shape\": mask_shape}\n",
    "        if (ind + 1) % 10 == 0:\n",
    "            print(\"writing {}/{} into mindrecord\".format(ind + 1, image_files_num))\n",
    "        writer.write_raw_data([row])\n",
    "    writer.commit()\n",
    "\n",
    "\n",
    "def create_maskrcnn_dataset(mindrecord_file, batch_size=2, device_num=1, rank_id=0,\n",
    "                            is_training=True, num_parallel_workers=2):\n",
    "    \"\"\"Create MaskRcnn dataset with MindDataset.\"\"\"\n",
    "    cv2.setNumThreads(0)\n",
    "    de.config.set_prefetch_size(8)\n",
    "    ds = de.MindDataset(mindrecord_file, columns_list=[\"image\", \"annotation\", \"mask\", \"mask_shape\"],\n",
    "                        num_shards=device_num, shard_id=rank_id,\n",
    "                        num_parallel_workers=4, shuffle=is_training)\n",
    "\n",
    "    decode = vision.Decode()\n",
    "    ds = ds.map(operations=decode, input_columns=[\"image\"])\n",
    "    compose_map_func = (lambda image, annotation, mask, mask_shape:\n",
    "                        preprocess_fn(image, annotation, mask, mask_shape, is_training))\n",
    "\n",
    "    if is_training:\n",
    "        ds = ds.map(operations=compose_map_func,\n",
    "                    input_columns=[\"image\", \"annotation\", \"mask\", \"mask_shape\"],\n",
    "                    output_columns=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\", \"mask\"],\n",
    "                    column_order=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\", \"mask\"],\n",
    "                    python_multiprocessing=False,\n",
    "                    num_parallel_workers=num_parallel_workers)\n",
    "        ds = ds.batch(batch_size, drop_remainder=True, pad_info={\"mask\": ([config.max_instance_count, None, None], 0)})\n",
    "\n",
    "    else:\n",
    "        ds = ds.map(operations=compose_map_func,\n",
    "                    input_columns=[\"image\", \"annotation\", \"mask\", \"mask_shape\"],\n",
    "                    output_columns=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\", \"mask\"],\n",
    "                    column_order=[\"image\", \"image_shape\", \"box\", \"label\", \"valid_num\", \"mask\"],\n",
    "                    num_parallel_workers=num_parallel_workers)\n",
    "        ds = ds.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def create_mindrecord_dir(prefix, mindrecord_dir, mindrecord_file):\n",
    "    if not os.path.isdir(mindrecord_dir):\n",
    "        os.makedirs(mindrecord_dir)\n",
    "    if os.path.isdir('val2017'):\n",
    "        print(\"Create Mindrecord.\")\n",
    "        data_to_mindrecord_byte_image(\"coco\", True, prefix)\n",
    "        print(\"Create Mindrecord Done, at {}\".format(mindrecord_dir))\n",
    "    else:\n",
    "        raise Exception(\"coco_root not exits.\")\n",
    "    while not os.path.exists(mindrecord_file + \".db\"):\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "def bbox2result_1image(bboxes, labels, num_classes):\n",
    "    \"\"\"Convert detection results to a list of numpy arrays.\n",
    "\n",
    "    Args:\n",
    "        bboxes (Tensor): shape (n, 5)\n",
    "        labels (Tensor): shape (n, )\n",
    "        num_classes (int): class number, including background class\n",
    "\n",
    "    Returns:\n",
    "        list(ndarray): bbox results of each class\n",
    "    \"\"\"\n",
    "    if bboxes.shape[0] == 0:\n",
    "        result = [np.zeros((0, 5), dtype=np.float32) for i in range(num_classes - 1)]\n",
    "    else:\n",
    "        result = [bboxes[labels == i, :] for i in range(num_classes - 1)]\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_seg_masks(mask_pred, det_bboxes, det_labels, img_meta, rescale, num_classes):\n",
    "    \"\"\"Get segmentation masks from mask_pred and bboxes\"\"\"\n",
    "    mask_pred = mask_pred.astype(np.float32)\n",
    "\n",
    "    cls_segms = [[] for _ in range(num_classes - 1)]\n",
    "    bboxes = det_bboxes[:, :4]\n",
    "    labels = det_labels + 1\n",
    "\n",
    "    ori_shape = img_meta[:2].astype(np.int32)\n",
    "    scale_factor = img_meta[2:].astype(np.int32)\n",
    "\n",
    "    if rescale:\n",
    "        img_h, img_w = ori_shape[:2]\n",
    "    else:\n",
    "        img_h = np.round(ori_shape[0] * scale_factor[0]).astype(np.int32)\n",
    "        img_w = np.round(ori_shape[1] * scale_factor[1]).astype(np.int32)\n",
    "\n",
    "    for i in range(bboxes.shape[0]):\n",
    "        bbox = (bboxes[i, :] / 1.0).astype(np.int32)\n",
    "        label = labels[i]\n",
    "        w = max(bbox[2] - bbox[0] + 1, 1)\n",
    "        h = max(bbox[3] - bbox[1] + 1, 1)\n",
    "        w = min(w, img_w - bbox[0])\n",
    "        h = min(h, img_h - bbox[1])\n",
    "        if w <= 0 or h <= 0:\n",
    "            print(\"there is invalid proposal bbox, index={} bbox={} w={} h={}\".format(i, bbox, w, h))\n",
    "            w = max(w, 1)\n",
    "            h = max(h, 1)\n",
    "        mask_pred_ = mask_pred[i, :, :]\n",
    "        im_mask = np.zeros((img_h, img_w), dtype=np.uint8)\n",
    "        bbox_mask = cv2.resize(mask_pred_, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "        bbox_mask = (bbox_mask > config.mask_thr_binary).astype(np.uint8)\n",
    "        im_mask[bbox[1]:bbox[1] + h, bbox[0]:bbox[0] + w] = bbox_mask\n",
    "\n",
    "        rle = maskUtils.encode(\n",
    "            np.array(im_mask[:, :, np.newaxis], order='F'))[0]\n",
    "        cls_segms[label - 1].append(rle)\n",
    "\n",
    "    return cls_segms\n",
    "\n",
    "\n",
    "def det2json(dataset, results):\n",
    "    \"\"\"convert det to json mode\"\"\"\n",
    "    cat_ids = dataset.getCatIds()\n",
    "    img_ids = dataset.getImgIds()\n",
    "    json_results = []\n",
    "    dataset_len = len(img_ids)\n",
    "    for idx in range(dataset_len):\n",
    "        img_id = img_ids[idx]\n",
    "        if idx == len(results): break\n",
    "        result = results[idx]\n",
    "        for label, result_label in enumerate(result):\n",
    "            bboxes = result_label\n",
    "            for i in range(bboxes.shape[0]):\n",
    "                data = dict()\n",
    "                data['image_id'] = img_id\n",
    "                data['bbox'] = xyxy2xywh(bboxes[i])\n",
    "                data['score'] = float(bboxes[i][4])\n",
    "                data['category_id'] = cat_ids[label]\n",
    "                json_results.append(data)\n",
    "    return json_results\n",
    "\n",
    "\n",
    "def xyxy2xywh(bbox):\n",
    "    _bbox = bbox.tolist()\n",
    "    return [\n",
    "        _bbox[0],\n",
    "        _bbox[1],\n",
    "        _bbox[2] - _bbox[0] + 1,\n",
    "        _bbox[3] - _bbox[1] + 1,\n",
    "        ]\n",
    "\n",
    "\n",
    "def segm2json(dataset, results):\n",
    "    \"\"\"convert segm to json mode\"\"\"\n",
    "    cat_ids = dataset.getCatIds()\n",
    "    img_ids = dataset.getImgIds()\n",
    "    bbox_json_results = []\n",
    "    segm_json_results = []\n",
    "\n",
    "    dataset_len = len(img_ids)\n",
    "    assert dataset_len == len(results)\n",
    "    for idx in range(dataset_len):\n",
    "        img_id = img_ids[idx]\n",
    "        if idx == len(results): break\n",
    "        det, seg = results[idx]\n",
    "        for label, det_label in enumerate(det):\n",
    "            bboxes = det_label\n",
    "            for i in range(bboxes.shape[0]):\n",
    "                data = dict()\n",
    "                data['image_id'] = img_id\n",
    "                data['bbox'] = xyxy2xywh(bboxes[i])\n",
    "                data['score'] = float(bboxes[i][4])\n",
    "                data['category_id'] = cat_ids[label]\n",
    "                bbox_json_results.append(data)\n",
    "\n",
    "            if len(seg) == 2:\n",
    "                segms = seg[0][label]\n",
    "                mask_score = seg[1][label]\n",
    "            else:\n",
    "                segms = seg[label]\n",
    "                mask_score = [bbox[4] for bbox in bboxes]\n",
    "            for i in range(bboxes.shape[0]):\n",
    "                data = dict()\n",
    "                data['image_id'] = img_id\n",
    "                data['score'] = float(mask_score[i])\n",
    "                data['category_id'] = cat_ids[label]\n",
    "                segms[i]['counts'] = segms[i]['counts'].decode()\n",
    "                data['segmentation'] = segms[i]\n",
    "                segm_json_results.append(data)\n",
    "    return bbox_json_results, segm_json_results\n",
    "\n",
    "\n",
    "def proposal2json(dataset, results):\n",
    "    \"\"\"convert proposal to json mode\"\"\"\n",
    "    img_ids = dataset.getImgIds()\n",
    "    json_results = []\n",
    "    dataset_len = dataset.get_dataset_size()*2\n",
    "    for idx in range(dataset_len):\n",
    "        img_id = img_ids[idx]\n",
    "        bboxes = results[idx]\n",
    "        for i in range(bboxes.shape[0]):\n",
    "            data = dict()\n",
    "            data['image_id'] = img_id\n",
    "            data['bbox'] = xyxy2xywh(bboxes[i])\n",
    "            data['score'] = float(bboxes[i][4])\n",
    "            data['category_id'] = 1\n",
    "            json_results.append(data)\n",
    "    return json_results\n",
    "\n",
    "\n",
    "def results2json(dataset, results, out_file):\n",
    "    \"\"\"convert result convert to json mode\"\"\"\n",
    "    result_files = dict()\n",
    "    if isinstance(results[0], list):\n",
    "        json_results = det2json(dataset, results)\n",
    "        result_files['bbox'] = '{}.{}.json'.format(out_file, 'bbox')\n",
    "        result_files['proposal'] = '{}.{}.json'.format(out_file, 'bbox')\n",
    "        with open(result_files['bbox'], 'w') as fp:\n",
    "            json.dump(json_results, fp)\n",
    "    elif isinstance(results[0], tuple):\n",
    "        json_results = segm2json(dataset, results)\n",
    "        result_files['bbox'] = '{}.{}.json'.format(out_file, 'bbox')\n",
    "        result_files['segm'] = '{}.{}.json'.format(out_file, 'segm')\n",
    "        with open(result_files['bbox'], 'w') as fp:\n",
    "            json.dump(json_results[0], fp)\n",
    "        with open(result_files['segm'], 'w') as fp:\n",
    "            json.dump(json_results[1], fp)\n",
    "    elif isinstance(results[0], np.ndarray):\n",
    "        json_results = proposal2json(dataset, results)\n",
    "        result_files['proposal'] = '{}.{}.json'.format(out_file, 'proposal')\n",
    "        with open(result_files['proposal'], 'w') as fp:\n",
    "            json.dump(json_results, fp)\n",
    "    else:\n",
    "        raise TypeError('invalid type of results')\n",
    "    return result_files\n",
    "\n",
    "\n",
    "def coco_eval(result_files, result_types, coco, max_dets=(100, 300, 1000), single_result=False):\n",
    "    \"\"\"coco eval for maskrcnn\"\"\"\n",
    "    _init_value = np.array(0.0)\n",
    "    summary_init = {\n",
    "        'Precision/mAP': _init_value,\n",
    "        'Precision/mAP@.50IOU': _init_value,\n",
    "        'Precision/mAP@.75IOU': _init_value,\n",
    "        'Precision/mAP (small)': _init_value,\n",
    "        'Precision/mAP (medium)': _init_value,\n",
    "        'Precision/mAP (large)': _init_value,\n",
    "        'Recall/AR@1': _init_value,\n",
    "        'Recall/AR@10': _init_value,\n",
    "        'Recall/AR@100': _init_value,\n",
    "        'Recall/AR@100 (small)': _init_value,\n",
    "        'Recall/AR@100 (medium)': _init_value,\n",
    "        'Recall/AR@100 (large)': _init_value,\n",
    "    }\n",
    "    anns = json.load(open(result_files['bbox']))\n",
    "    if not anns:\n",
    "        return summary_init\n",
    "    if isinstance(coco, str):\n",
    "        coco = COCO(coco)\n",
    "    assert isinstance(coco, COCO)\n",
    "\n",
    "    for res_type in result_types:\n",
    "        result_file = result_files[res_type]\n",
    "        assert result_file.endswith('.json')\n",
    "\n",
    "        coco_dets = coco.loadRes(result_file)\n",
    "        gt_img_ids = coco.getImgIds()\n",
    "        det_img_ids = coco_dets.getImgIds()\n",
    "        iou_type = 'bbox' if res_type == 'proposal' else res_type\n",
    "        cocoEval = COCOeval(coco, coco_dets, iou_type)\n",
    "        if res_type == 'proposal':\n",
    "            cocoEval.params.useCats = 0\n",
    "            cocoEval.params.maxDets = list(max_dets)\n",
    "\n",
    "        tgt_ids = gt_img_ids if not single_result else det_img_ids\n",
    "\n",
    "        if single_result:\n",
    "            res_dict = dict()\n",
    "            for id_i in tgt_ids:\n",
    "                cocoEval = COCOeval(coco, coco_dets, iou_type)\n",
    "                if res_type == 'proposal':\n",
    "                    cocoEval.params.useCats = 0\n",
    "                    cocoEval.params.maxDets = list(max_dets)\n",
    "\n",
    "                cocoEval.params.imgIds = [id_i]\n",
    "                cocoEval.evaluate()\n",
    "                cocoEval.accumulate()\n",
    "                cocoEval.summarize()\n",
    "                res_dict.update({coco.imgs[id_i]['file_name']: cocoEval.stats[1]})\n",
    "\n",
    "        cocoEval = COCOeval(coco, coco_dets, iou_type)\n",
    "        if res_type == 'proposal':\n",
    "            cocoEval.params.useCats = 0\n",
    "            cocoEval.params.maxDets = list(max_dets)\n",
    "\n",
    "        cocoEval.params.imgIds = tgt_ids\n",
    "        cocoEval.evaluate()\n",
    "        cocoEval.accumulate()\n",
    "        cocoEval.summarize()\n",
    "\n",
    "        summary_metrics = {\n",
    "            'Precision/mAP': cocoEval.stats[0],\n",
    "            'Precision/mAP@.50IOU': cocoEval.stats[1],\n",
    "            'Precision/mAP@.75IOU': cocoEval.stats[2],\n",
    "            'Precision/mAP (small)': cocoEval.stats[3],\n",
    "            'Precision/mAP (medium)': cocoEval.stats[4],\n",
    "            'Precision/mAP (large)': cocoEval.stats[5],\n",
    "            'Recall/AR@1': cocoEval.stats[6],\n",
    "            'Recall/AR@10': cocoEval.stats[7],\n",
    "            'Recall/AR@100': cocoEval.stats[8],\n",
    "            'Recall/AR@100 (small)': cocoEval.stats[9],\n",
    "            'Recall/AR@100 (medium)': cocoEval.stats[10],\n",
    "            'Recall/AR@100 (large)': cocoEval.stats[11],\n",
    "        }\n",
    "\n",
    "    return summary_metrics\n",
    "\n",
    "\n",
    "def get_img_size(file_name):\n",
    "    img = Image.open(file_name)\n",
    "    return img.size\n",
    "\n",
    "def get_resize_ratio(img_size):\n",
    "    dst_width = 1280\n",
    "    dst_height = 768\n",
    "    org_width, org_height = img_size\n",
    "    resize_ratio = dst_width / org_width\n",
    "    if resize_ratio > dst_height / org_height:\n",
    "        resize_ratio = dst_height / org_height\n",
    "\n",
    "    return resize_ratio\n",
    "\n",
    "\n",
    "def get_eval_result(bbox_file, segm_file, ann_file, img_name, img_path):\n",
    "    \"\"\" Get metrics result according to the annotation file and result file\"\"\"\n",
    "    with open(bbox_file) as b, open(segm_file) as s:\n",
    "        bboxes = json.load(b)\n",
    "        segms = json.load(s)\n",
    "        data_coco = COCO(ann_file)\n",
    "        img_id = -1\n",
    "        for k, v in data_coco.imgs.items():\n",
    "            if v['file_name'] == img_name:\n",
    "                img_id = k\n",
    "        img = cv2.imread(img_path + \"/\" + img_name)\n",
    "        img1 = img.copy()\n",
    "        for d in bboxes:\n",
    "            if d['image_id'] == img_id:\n",
    "                box = d['bbox']\n",
    "                x, y, w, h = box\n",
    "                a = (int(x), int(y))\n",
    "                b = (int(x + w), int(y + h))\n",
    "                img1 = cv2.rectangle(img1, a, b, (0, 255, 255), 2)\n",
    "                img1 = cv2.putText(img1, \"{} {:.3f}\".format(config.coco_classes[int(d['category_id'])], d['score']),\n",
    "                                   (b[0], a[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
    "        cv2.imshow(\"detect\", img1)\n",
    "        cv2.waitKey()\n",
    "        color = (0, 0.6, 0.6)\n",
    "        for d in segms:\n",
    "            if d['image_id'] == img_id:\n",
    "                mask = maskUtils.decode(d['segmentation'])\n",
    "                mask = np.where(mask > 0, 1, 0).astype(np.uint8)\n",
    "                for c in range(3):\n",
    "                    img[:, :, c] = np.where(mask == 1, img[:, :, c] * 0.5 + 0.5 * color[c] * 255, img[:, :, c])\n",
    "        cv2.imshow(\"mask\", img)\n",
    "        cv2.waitKey()\n",
    "\n",
    "\n",
    "class config:\n",
    "    device_target = 'CPU'\n",
    "    # Training options\n",
    "    img_width = 1280\n",
    "    img_height = 768\n",
    "    keep_ratio = True\n",
    "    flip_ratio = 0.5\n",
    "    expand_ratio = 1.0\n",
    "    max_instance_count = 128\n",
    "    mask_shape = [28, 28]\n",
    "    # anchor\n",
    "    feature_shapes = [[192, 320], [96, 160], [48, 80], [24, 40], [12, 20]]\n",
    "    anchor_scales = [8]\n",
    "    anchor_ratios = [0.5, 1.0, 2.0]\n",
    "    anchor_strides = [4, 8, 16, 32, 64]\n",
    "    num_anchors = 3\n",
    "    # resnet\n",
    "    resnet_block = [3, 4, 6, 3]\n",
    "    resnet_in_channels = [64, 256, 512, 1024]\n",
    "    resnet_out_channels = [256, 512, 1024, 2048]\n",
    "    # fpn\n",
    "    fpn_in_channels = [256, 512, 1024, 2048]\n",
    "    fpn_out_channels = 256\n",
    "    fpn_num_outs = 5\n",
    "    # rpn\n",
    "    rpn_in_channels = 256\n",
    "    rpn_feat_channels = 256\n",
    "    rpn_loss_cls_weight = 1.0\n",
    "    rpn_loss_reg_weight = 1.0\n",
    "    rpn_cls_out_channels = 1\n",
    "    rpn_target_means = [0., 0., 0., 0.]\n",
    "    rpn_target_stds = [1.0, 1.0, 1.0, 1.0]\n",
    "    # rpn train\n",
    "    rpn_proposal_nms_across_levels = False\n",
    "    rpn_proposal_nms_pre = 2000\n",
    "    rpn_proposal_nms_post = 2000\n",
    "    rpn_proposal_max_num = 2000\n",
    "    rpn_proposal_nms_thr = 0.7\n",
    "    rpn_proposal_min_bbox_size = 0\n",
    "    # rpn test\n",
    "    rpn_nms_across_levels = False\n",
    "    rpn_nms_pre = 1000\n",
    "    rpn_nms_post = 1000\n",
    "    rpn_max_num = 1000\n",
    "    rpn_nms_thr = 0.5\n",
    "    rpn_min_bbox_min_size = 0\n",
    "    # bbox assign sampler\n",
    "    neg_iou_thr = 0.3\n",
    "    pos_iou_thr = 0.7\n",
    "    min_pos_iou = 0.3\n",
    "    num_bboxes = 245520\n",
    "    num_gts = 128\n",
    "    num_expected_neg = 256\n",
    "    num_expected_pos = 128\n",
    "    # bbox assign sampler stage2\n",
    "    neg_iou_thr_stage2 = 0.5\n",
    "    pos_iou_thr_stage2 = 0.5\n",
    "    min_pos_iou_stage2 = 0.5\n",
    "    num_bboxes_stage2 = 2000\n",
    "    num_expected_pos_stage2 = 128\n",
    "    num_expected_neg_stage2 = 512\n",
    "    num_expected_total_stage2 = 512\n",
    "    # rcnn\n",
    "    rcnn_num_layers = 2\n",
    "    rcnn_in_channels = 256\n",
    "    rcnn_fc_out_channels = 1024\n",
    "    rcnn_mask_out_channels = 256\n",
    "    rcnn_loss_cls_weight = 1\n",
    "    rcnn_loss_reg_weight = 1\n",
    "    rcnn_loss_mask_fb_weight = 1\n",
    "    rcnn_target_means = [0., 0., 0., 0.]\n",
    "    rcnn_target_stds = [0.1, 0.1, 0.2, 0.2]\n",
    "    # proposal\n",
    "    activate_num_classes = 2\n",
    "    use_sigmoid_cls = True\n",
    "    # test proposal\n",
    "    test_score_thr = 0.002\n",
    "    test_iou_thr = 0.3\n",
    "    test_max_per_img = 100\n",
    "    test_batch_size = 1\n",
    "    rpn_head_use_sigmoid = True\n",
    "    rpn_head_weight = 1.0\n",
    "    mask_thr_binary = 0.5\n",
    "    # roi align\n",
    "    class roi_layer:\n",
    "        type = 'RoIAlign'\n",
    "        out_size = 7\n",
    "        mask_out_size = 14\n",
    "        sample_num = 2\n",
    "    roi_align_out_channels = 256\n",
    "    roi_align_featmap_strides = [4, 8, 16, 32]\n",
    "    roi_align_finest_scale = 56\n",
    "    roi_sample_num = 640\n",
    "    # train\n",
    "    batch_size = 8\n",
    "    loss_scale = 1024\n",
    "    momentum = 0.91\n",
    "    weight_decay = 0.0001  # 1e-4\n",
    "    pretrain_epoch_size = 0\n",
    "    epoch_size = 20\n",
    "\n",
    "    num_classes = 81\n",
    "    test_dir = 'test_img'\n",
    "    mindrecord_dir = 'val2017'\n",
    "    instance_set = \"annotations/instances_{}.json\"\n",
    "    coco_root = '.'\n",
    "    val_data_type = 'val2017'\n",
    "    train_data_type = 'val2017'\n",
    "    coco_classes = ['background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "                     'train', 'truck', 'boat', 'traffic light', 'fire hydrant',\n",
    "                     'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',\n",
    "                     'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',\n",
    "                     'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "                     'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "                     'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "                     'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "                     'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "                     'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "                     'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "                     'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "                     'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
    "                     'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "                     'teddy bear', 'hair drier', 'toothbrush']\n",
    "\n",
    "\n",
    "def train():\n",
    "    rank = 0\n",
    "    prefix = \"MaskRcnn.mindrecord\"\n",
    "    mindrecord_dir = 'val2017'\n",
    "    mindrecord_file = os.path.join(mindrecord_dir, prefix + \"0\")\n",
    "    if rank == 0 and not os.path.exists(mindrecord_file):\n",
    "        create_mindrecord_dir(prefix, mindrecord_dir, mindrecord_file)\n",
    "    dataset = create_maskrcnn_dataset(mindrecord_file, batch_size=config.batch_size, device_num=1, rank_id=0)\n",
    "    net = MaskRCNN(config)\n",
    "    net = net.set_train()\n",
    "    loss = LossNet()\n",
    "    lr = Tensor(0.0001, mstype.float32)\n",
    "    opt = Momentum(params=net.trainable_params(), learning_rate=lr, momentum=0.9)\n",
    "\n",
    "    def forward_fn(img_data, img_metas, gt_bboxes, gt_labels, gt_num, gt_mask):\n",
    "        output = net(img_data, img_metas, gt_bboxes, gt_labels, gt_num, gt_mask)\n",
    "        l = loss(*output)\n",
    "        return l\n",
    "    grad_fn = ops.value_and_grad(forward_fn, None, opt.parameters, has_aux=False)\n",
    "\n",
    "    def train_step(img_data, img_metas, gt_bboxes, gt_labels, gt_num, gt_mask):\n",
    "        (loss), grads = grad_fn(img_data, img_metas, gt_bboxes, gt_labels, gt_num, gt_mask)\n",
    "        loss = ops.depend(loss, opt(grads))\n",
    "        return loss\n",
    "    for epoch in range(config.epoch_size):\n",
    "        step = 0\n",
    "        for data in dataset.create_dict_iterator(output_numpy=True, num_epochs=1):\n",
    "            img_data = data['image']\n",
    "            img_metas = data['image_shape']\n",
    "            gt_bboxes = data['box']\n",
    "            gt_labels = data['label']\n",
    "            gt_num = data['valid_num']\n",
    "            gt_mask = data[\"mask\"]\n",
    "            l = train_step(Tensor(img_data, dtype=mstype.float32), Tensor(img_metas, dtype=mstype.float32),\n",
    "                              Tensor(gt_bboxes, dtype=mstype.float32), Tensor(gt_labels, dtype=mstype.float32),\n",
    "                              Tensor(gt_num, dtype=mstype.float32), Tensor(gt_mask, dtype=mstype.float32))\n",
    "            print(\"epoch:\", epoch, \" step:\", step, \" loss:\", l)\n",
    "            step += 1\n",
    "    ms.save_checkpoint(net, \"./ckpt_\" + str(rank) + \"/mask_rcnn.ckpt\")\n",
    "    print('---------train done-----------')\n",
    "\n",
    "\n",
    "def eval_():\n",
    "    device_target = config.device_target\n",
    "    context.set_context(mode=context.GRAPH_MODE, device_target=device_target)\n",
    "\n",
    "    config.mindrecord_dir = os.path.join(config.coco_root, config.test_dir)\n",
    "    prefix = \"MaskRcnn_eval.mindrecord\"\n",
    "    mindrecord_dir = config.mindrecord_dir\n",
    "    mindrecord_file = os.path.join(mindrecord_dir, prefix)\n",
    "    if not os.path.exists(mindrecord_file):\n",
    "        if not os.path.isdir(mindrecord_dir):\n",
    "            os.makedirs(mindrecord_dir)\n",
    "        if os.path.isdir(config.coco_root):\n",
    "            print(\"Create Mindrecord.\")\n",
    "            data_to_mindrecord_byte_image(\"coco\", False, prefix, file_num=1)\n",
    "            print(\"Create Mindrecord Done, at {}\".format(mindrecord_dir))\n",
    "        else:\n",
    "            print(\"coco_root not exits.\")\n",
    "\n",
    "    print(\"Start Eval!\")\n",
    "\n",
    "    ds = create_maskrcnn_dataset(mindrecord_file, batch_size=config.test_batch_size, is_training=False)\n",
    "\n",
    "    net = MaskRCNN(config)\n",
    "    param_dict = load_checkpoint('./ckpt_0/mask_rcnn.ckpt')\n",
    "    load_param_into_net(net, param_dict)\n",
    "    net.set_train(False)\n",
    "\n",
    "    eval_iter = 0\n",
    "    total = ds.get_dataset_size()\n",
    "    outputs = []\n",
    "    dataset_coco = COCO('test_annotations/instances_val2017.json')\n",
    "\n",
    "    print(\"\\n========================================\\n\")\n",
    "    print(\"total images num: \", total)\n",
    "    print(\"Processing, please wait a moment.\")\n",
    "    max_num = 128\n",
    "    for data in ds.create_dict_iterator(output_numpy=True, num_epochs=1):\n",
    "\n",
    "        img_data = data['image']\n",
    "        img_metas = data['image_shape']\n",
    "        gt_bboxes = data['box']\n",
    "        gt_labels = data['label']\n",
    "        gt_num = data['valid_num']\n",
    "        gt_mask = data[\"mask\"]\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # run net\n",
    "        output = net(Tensor(img_data, dtype=mstype.float32), Tensor(img_metas, dtype=mstype.float32), Tensor(gt_bboxes, dtype=mstype.float32),\n",
    "                     Tensor(gt_labels, dtype=mstype.float32), Tensor(gt_num, dtype=mstype.float32), Tensor(gt_mask, dtype=mstype.float32))\n",
    "        end = time.time()\n",
    "        print(\"Iter {} cost time {}\".format(eval_iter, end - start))\n",
    "\n",
    "        # output\n",
    "        all_bbox = output[0]\n",
    "        all_label = output[1]\n",
    "        all_mask = output[2]\n",
    "        all_mask_fb = output[3]\n",
    "        print(all_bbox.shape)\n",
    "        print(all_mask.shape, np.sum(all_mask.asnumpy()[0]))\n",
    "\n",
    "        for j in range(config.test_batch_size):\n",
    "            all_bbox_squee = np.squeeze(all_bbox.asnumpy()[j, :, :])\n",
    "            all_label_squee = np.squeeze(all_label.asnumpy()[j, :, :])\n",
    "            all_mask_squee = np.squeeze(all_mask.asnumpy()[j, :, :])\n",
    "            all_mask_fb_squee = np.squeeze(all_mask_fb.asnumpy()[j, :, :, :])\n",
    "\n",
    "            all_bboxes_tmp_mask = all_bbox_squee[all_mask_squee, :]\n",
    "            all_labels_tmp_mask = all_label_squee[all_mask_squee]\n",
    "            all_mask_fb_tmp_mask = all_mask_fb_squee[all_mask_squee, :, :]\n",
    "\n",
    "            if all_bboxes_tmp_mask.shape[0] > max_num:\n",
    "                inds = np.argsort(-all_bboxes_tmp_mask[:, -1])\n",
    "                inds = inds[:max_num]\n",
    "                all_bboxes_tmp_mask = all_bboxes_tmp_mask[inds]\n",
    "                all_labels_tmp_mask = all_labels_tmp_mask[inds]\n",
    "                all_mask_fb_tmp_mask = all_mask_fb_tmp_mask[inds]\n",
    "\n",
    "            bbox_results = bbox2result_1image(all_bboxes_tmp_mask, all_labels_tmp_mask, config.num_classes)\n",
    "            segm_results = get_seg_masks(all_mask_fb_tmp_mask, all_bboxes_tmp_mask, all_labels_tmp_mask, img_metas[j],\n",
    "                                         True, config.num_classes)\n",
    "            outputs.append((bbox_results, segm_results))\n",
    "\n",
    "            eval_iter = eval_iter + 1\n",
    "\n",
    "    eval_types = [\"bbox\", \"segm\"]\n",
    "    result_files = results2json(dataset_coco, outputs, \"./results.pkl\")\n",
    "    metrics = coco_eval(result_files, eval_types, dataset_coco, single_result=False)\n",
    "    print(metrics)\n",
    "\n",
    "    \n",
    "    train()\n",
    "    eval_()\n",
    "    get_eval_result('results.pkl.bbox.json', 'results.pkl.segm.json', \"test_annotations/instances_val2017.json\",\n",
    "                    '000000407646.jpg', 'test_img')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
